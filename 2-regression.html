<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An Introduction to Statistical and Data Sciences via R</title>
  <meta name="description" content="An open-source and fully-reproducible electronic textbook bridging the gap between traditional introductory statistics and data science courses.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="An Introduction to Statistical and Data Sciences via R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://moderndive.com/" />
  <meta property="og:image" content="http://moderndive.com/images/logos/book_cover.png" />
  <meta property="og:description" content="An open-source and fully-reproducible electronic textbook bridging the gap between traditional introductory statistics and data science courses." />
  <meta name="github-repo" content="ismayc/moderndiver-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An Introduction to Statistical and Data Sciences via R" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic textbook bridging the gap between traditional introductory statistics and data science courses." />
  <meta name="twitter:image" content="http://moderndive.com/images/logos/book_cover.png" />

<meta name="author" content="Chester Ismay and Albert Y. Kim">


<meta name="date" content="2018-01-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="images/logos/favicons/apple-touch-icon.png">
  <link rel="shortcut icon" href="images/logos/favicons/favicon.ico" type="image/x-icon">
<link rel="prev" href="index.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#intro-for-students"><i class="fa fa-check"></i><b>1.1</b> Introduction for students</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> What you will learn from this book</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#pipeline"><i class="fa fa-check"></i><b>1.1.2</b> Data/science pipeline</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#reproducible"><i class="fa fa-check"></i><b>1.1.3</b> Reproducible research</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#final-note-for-students"><i class="fa fa-check"></i><b>1.1.4</b> Final note for students</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#intro-instructors"><i class="fa fa-check"></i><b>1.2</b> Introduction for instructors</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i><b>1.2.1</b> Who is this book for?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#connect-contribute"><i class="fa fa-check"></i><b>1.3</b> Connect and contribute</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#about-book"><i class="fa fa-check"></i><b>1.4</b> About this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-regression.html"><a href="2-regression.html"><i class="fa fa-check"></i><b>2</b> Data Modeling with Regression</a><ul>
<li class="chapter" data-level="" data-path="2-regression.html"><a href="2-regression.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="2.1" data-path="2-regression.html"><a href="2-regression.html#five-regression-models---the-5rm"><i class="fa fa-check"></i><b>2.1</b> Five Regression Models - The 5RM</a></li>
<li class="chapter" data-level="2.2" data-path="2-regression.html"><a href="2-regression.html#model1"><i class="fa fa-check"></i><b>2.2</b> 5RM#1: Understanding Teacher Evaluations</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-regression.html"><a href="2-regression.html#model1EDA"><i class="fa fa-check"></i><b>2.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-regression.html"><a href="2-regression.html#model1table"><i class="fa fa-check"></i><b>2.2.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-regression.html"><a href="2-regression.html#model1points"><i class="fa fa-check"></i><b>2.2.3</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.2.4" data-path="2-regression.html"><a href="2-regression.html#model1residuals"><i class="fa fa-check"></i><b>2.2.4</b> Residual analysis</a></li>
<li class="chapter" data-level="2.2.5" data-path="2-regression.html"><a href="2-regression.html#your-turn"><i class="fa fa-check"></i><b>2.2.5</b> Your Turn</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-regression.html"><a href="2-regression.html#model2"><i class="fa fa-check"></i><b>2.3</b> 5RM#2: Life Expectancy</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-regression.html"><a href="2-regression.html#model2EDA"><i class="fa fa-check"></i><b>2.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-regression.html"><a href="2-regression.html#model2table"><i class="fa fa-check"></i><b>2.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-regression.html"><a href="2-regression.html#model2residuals"><i class="fa fa-check"></i><b>2.3.3</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.3.4" data-path="2-regression.html"><a href="2-regression.html#model2residuals"><i class="fa fa-check"></i><b>2.3.4</b> Residual analysis</a></li>
<li class="chapter" data-level="2.3.5" data-path="2-regression.html"><a href="2-regression.html#your-turn-1"><i class="fa fa-check"></i><b>2.3.5</b> Your turn</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-regression.html"><a href="2-regression.html#model3"><i class="fa fa-check"></i><b>2.4</b> 5RM#3: Credit Card Balance</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-regression.html"><a href="2-regression.html#model3EDA"><i class="fa fa-check"></i><b>2.4.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-regression.html"><a href="2-regression.html#model3table"><i class="fa fa-check"></i><b>2.4.2</b> Multiple regression</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-regression.html"><a href="2-regression.html#model3points"><i class="fa fa-check"></i><b>2.4.3</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.4.4" data-path="2-regression.html"><a href="2-regression.html#model3residuals"><i class="fa fa-check"></i><b>2.4.4</b> Residual analysis</a></li>
<li class="chapter" data-level="2.4.5" data-path="2-regression.html"><a href="2-regression.html#your-turn-2"><i class="fa fa-check"></i><b>2.4.5</b> Your turn</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-regression.html"><a href="2-regression.html#model4"><i class="fa fa-check"></i><b>2.5</b> 5RM#4: Teacher Evaluations Part II</a><ul>
<li class="chapter" data-level="2.5.1" data-path="2-regression.html"><a href="2-regression.html#model4EDA"><i class="fa fa-check"></i><b>2.5.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.5.2" data-path="2-regression.html"><a href="2-regression.html#model4table"><i class="fa fa-check"></i><b>2.5.2</b> Multiple regression</a></li>
<li class="chapter" data-level="2.5.3" data-path="2-regression.html"><a href="2-regression.html#mutiple-regression-with-interaction-effects"><i class="fa fa-check"></i><b>2.5.3</b> Mutiple regression with interaction effects</a></li>
<li class="chapter" data-level="2.5.4" data-path="2-regression.html"><a href="2-regression.html#model4points"><i class="fa fa-check"></i><b>2.5.4</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.5.5" data-path="2-regression.html"><a href="2-regression.html#model4residuals"><i class="fa fa-check"></i><b>2.5.5</b> Residual analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="2-regression.html"><a href="2-regression.html#model5"><i class="fa fa-check"></i><b>2.6</b> 5RM#5: Biographical Movies</a><ul>
<li class="chapter" data-level="2.6.1" data-path="2-regression.html"><a href="2-regression.html#log-transformations"><i class="fa fa-check"></i><b>2.6.1</b> log-transformations</a></li>
<li class="chapter" data-level="2.6.2" data-path="2-regression.html"><a href="2-regression.html#model5EDA"><i class="fa fa-check"></i><b>2.6.2</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="2.6.3" data-path="2-regression.html"><a href="2-regression.html#model5table"><i class="fa fa-check"></i><b>2.6.3</b> Multiple regression</a></li>
<li class="chapter" data-level="2.6.4" data-path="2-regression.html"><a href="2-regression.html#model5points"><i class="fa fa-check"></i><b>2.6.4</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="2.6.5" data-path="2-regression.html"><a href="2-regression.html#model5residuals"><i class="fa fa-check"></i><b>2.6.5</b> Residual analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="2-regression.html"><a href="2-regression.html#inference-for-regression"><i class="fa fa-check"></i><b>2.7</b> Inference for regression</a></li>
<li class="chapter" data-level="2.8" data-path="2-regression.html"><a href="2-regression.html#other-topics"><i class="fa fa-check"></i><b>2.8</b> Other topics</a><ul>
<li class="chapter" data-level="2.8.1" data-path="2-regression.html"><a href="2-regression.html#correlationcoefficient"><i class="fa fa-check"></i><b>2.8.1</b> Correlation coefficient</a></li>
<li class="chapter" data-level="2.8.2" data-path="2-regression.html"><a href="2-regression.html#leastsquares"><i class="fa fa-check"></i><b>2.8.2</b> Best fitting line</a></li>
<li class="chapter" data-level="2.8.3" data-path="2-regression.html"><a href="2-regression.html#underthehood"><i class="fa fa-check"></i><b>2.8.3</b> How does <code>get_regression_table()</code> work?</a></li>
<li class="chapter" data-level="2.8.4" data-path="2-regression.html"><a href="2-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>2.8.4</b> Simpson’s Paradox</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical and Data Sciences via R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='http://moderndive.com/images/logos/wide_format.png' alt="ModernDive">
</html>
<div id="regression" class="section level1">
<h1><span class="header-section-number">2</span> Data Modeling with Regression</h1>
<p>Now that we are equipped with data visualization skills from Chapter <a href="#viz"><strong>??</strong></a>, data wrangling skills from Chapter <a href="#wrangling"><strong>??</strong></a>, and an understanding of the “tidy” data format from Chapter <a href="#tidy"><strong>??</strong></a>, we now proceed with data modeling. The fundamental premise of data modeling is <em>to model the relationship</em> between:</p>
<ul>
<li>An outcome variable <span class="math inline">\(y\)</span>, also called a dependent variable</li>
<li>Explanatory/predictor variables <span class="math inline">\(\vec{x}\)</span>, also called independent variables and covariates. The arrow on top of the <span class="math inline">\(x\)</span> indicates that we have a <em>vector</em> or a series of values.</li>
</ul>
<p>Why do we have two different labels, explanatory and predictor, for the variables <span class="math inline">\(\vec{x}\)</span>? That’s because data modeling can be viewed through two lenses</p>
<ol style="list-style-type: decimal">
<li><strong>Modeling for explanation</strong>: You want to study the relationship between an outcome variable <span class="math inline">\(y\)</span> and a set of explanatory variables, determine the significance of any found relationships, and have measures summarizing these. For example: “Does knowing a population’s smoking habits explain their lung cancer prevalence?”</li>
<li><strong>Modeling for prediction</strong>: You want to predict an outcome variable <span class="math inline">\(y\)</span> based on the information contained in a set of predictor variables. You don’t care so much about understanding how all the variables relate and interact, but so long as you can make good predictions about <span class="math inline">\(y\)</span>, you’re fine. For example: “Can we predict whether someone will enjoy a recommended movie based on their previous movie ratings?”</li>
</ol>
<p>Data modeling is used in a wide variety of fields, including statistical inference, causal inference, artificial intelligence, and machine learning. There are many techniques for data modeling, such as tree-based models, neural networks/deep learning, and more. However, we’ll focus on one particular technique: <em>linear regression</em>, one of the most commonly-used and easy to understand approaches to modeling. Linear regression involves:</p>
<ul>
<li>An outcome variable <span class="math inline">\(y\)</span> that is <em>numerical</em></li>
<li>Explanatory/predictor variables <span class="math inline">\(\vec{x}\)</span> that are either <em>numerical</em> or <em>categorical</em></li>
</ul>
<p>In this chapter, we’ll start considering a wider array of datasets, all easily accessible via R packages. We will also discuss the concept of <em>correlation</em> and how it is frequently incorrectly used to imply <em>causation</em>.</p>
<div id="needed-packages" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter. If needed, read Section <a href="#packages"><strong>??</strong></a> for information on how to install and load R packages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
<span class="co">#remotes::install_github(&quot;moderndive/moderndive&quot;)</span>
<span class="kw">library</span>(moderndive)</code></pre></div>
<p>Notice we load a new package called <code>moderndive</code> thus you’ll need to install this once. This is an accompaniment package to the ModernDive book that includes 3 useful functions for linear regression.</p>
<!--
1. `get_regression_table()`: Fit a linear regression and get the *regression table*
1. `get_regression_points()`: Fit a linear regression and get all the relevant points, including the *fitted value* $\widehat{y}$ and *residuals*
1. `get_regression_summaries()`: Fit a linear regression and get summary statistics about the regression, including values called $R^2$ and $R^2$-adjusted.
-->
</div>
<div id="five-regression-models---the-5rm" class="section level2">
<h2><span class="header-section-number">2.1</span> Five Regression Models - The 5RM</h2>
<p>As stated in the introduction, linear regression can be used to model the relationship between</p>
<ul>
<li>An outcome variable <span class="math inline">\(y\)</span> that is <em>numerical</em></li>
<li>Explanatory/predictor variables <span class="math inline">\(\vec{x}\)</span> that are either <em>numerical</em> or <em>categorical</em></li>
</ul>
<p>Whereas there is always only one numerical outcome variable <span class="math inline">\(y\)</span>, we have choices on both the number and the type of explanatory/predictor variables <span class="math inline">\(\vec{x}\)</span> to use. In this Chapter, we’re going to cover five regression models which we term the “5RM”:</p>
<ol style="list-style-type: decimal">
<li>5RM#1: A single numerical explanatory/predictor variable <span class="math inline">\(x\)</span>. This scenario is known as <em>simple linear regression</em>. We’ll be using the <code>evals</code> dataset of instructor evaluations at the University of Texas, Austin.</li>
<li>5RM#2: A single categorical explanatory/predictor variable <span class="math inline">\(x\)</span>. We’ll be using the <code>gapminder</code> dataset of international development data.</li>
<li>5RM#3: Two numerical explanatory/predictor variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. This is the first scenario of <em>multiple regression</em> given that there are now more than one explanatory/predictor variable. We’ll be using the <code>Credit</code> dataset of credit card balance data.</li>
<li>5RM#4: One numerical and one categorical explanatory/predictor variable. We’ll cover <em>interaction models</em> here. We’ll revisit the <code>evals</code> dataset here.</li>
<li>5RM#5: Two categorical explanatory/predictor variables. We’ll be using the <code>biopics</code> dataset of movie data.</li>
</ol>
</div>
<div id="model1" class="section level2">
<h2><span class="header-section-number">2.2</span> 5RM#1: Understanding Teacher Evaluations</h2>
<p>Why do some professors at universities and colleges get high teaching evaluations from students while others don’t? What factors can explain these differences? Are there biases? These are questions that are interest to professors and administrators, as teaching evaluations are among the criteria considered for promotion to tenure.</p>
<p>Researchers at the University of Texas in Austin tried to answer this question: what factors can explain differences in instructor’s teaching evaluation scores? To this end, the collected information on <span class="math inline">\(n=463\)</span> instructors. A full description of the study can be found at <a href="https://www.openintro.org/stat/data/?data=evals">openintro.org</a>, but let’s summarize the variables that were collected:</p>
<ul>
<li>Outcome variable <span class="math inline">\(y\)</span>: Average teaching score, based on students evaluations between 1 and 5</li>
<li>Explanatory variables <span class="math inline">\(x\)</span>
<ul>
<li>their rank: teaching, tenure track, or tenured</li>
<li>their ethnicity: minority or non-minority</li>
<li>their (binary) gender: male or female</li>
<li>their language: whether or not English was their mother tongue</li>
<li>their age:</li>
<li>their average “beauty” rating, based on a panel of 6 students’ scores between 1 and 10.</li>
</ul></li>
</ul>
<p>Let’s load the data and <code>select()</code> only the 7 variables listed above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load(url(&quot;http://www.openintro.org/stat/data/evals.RData&quot;))</span>
evals &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_csv</span>(<span class="st">&quot;~/Desktop/evals.csv&quot;</span>)
evals &lt;-<span class="st"> </span>evals <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(score, bty_avg, ethnicity, gender, language, age, rank)</code></pre></div>
<p>In this section we’ll try to explain differences in instructor evaluations scores as a function of their beauty scores. We’ll model the relationship between these two variables with a particular kind of linear regression called <em>simple linear regression</em>. Simple linear regression is the most basic form of linear regression where we have</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, in this case teaching <code>score</code></li>
<li>A single numerical explanatory/predictor variable <span class="math inline">\(x\)</span>, in this case <code>bty_avg</code></li>
</ol>
<div id="model1EDA" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Exploratory data analysis</h3>
<p>A crucial step before doing any kind of modeling or analysis however is performing an <em>exploratory data analysis</em>, or EDA, of all our data. EDA can give you a sense of the distribution of data, whether there are outliers and/or missing values, but most importantly it can inform how to build your model. There are many approaches to EDA, here are three:</p>
<ol style="list-style-type: decimal">
<li>Most fundamentally, just looking at the raw values, in a spreadsheet for example. While this may seem trivial, many people ignore this crucial step!</li>
<li>Compute summary statistics likes means, medians, and standard deviations.</li>
<li>Create data visualizations.</li>
</ol>
<p>We start off by looking at the raw values. You can do this by running <code>View(evals)</code> in the console to pop-up the spreadsheet viewer. Here is a snapshot of 5 randomly chosen rows:</p>
<table>
<caption><span id="tab:unnamed-chunk-5">Table 2.1: </span>Random sample of 5 instructors</caption>
<thead>
<tr class="header">
<th align="right">score</th>
<th align="right">bty_avg</th>
<th align="left">ethnicity</th>
<th align="left">gender</th>
<th align="left">language</th>
<th align="right">age</th>
<th align="left">rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4.8</td>
<td align="right">4.17</td>
<td align="left">not minority</td>
<td align="left">male</td>
<td align="left">english</td>
<td align="right">64</td>
<td align="left">tenured</td>
</tr>
<tr class="even">
<td align="right">5.0</td>
<td align="right">3.33</td>
<td align="left">minority</td>
<td align="left">male</td>
<td align="left">english</td>
<td align="right">50</td>
<td align="left">teaching</td>
</tr>
<tr class="odd">
<td align="right">4.2</td>
<td align="right">2.67</td>
<td align="left">not minority</td>
<td align="left">male</td>
<td align="left">english</td>
<td align="right">42</td>
<td align="left">tenured</td>
</tr>
<tr class="even">
<td align="right">3.4</td>
<td align="right">2.83</td>
<td align="left">not minority</td>
<td align="left">male</td>
<td align="left">english</td>
<td align="right">57</td>
<td align="left">tenured</td>
</tr>
<tr class="odd">
<td align="right">4.3</td>
<td align="right">4.17</td>
<td align="left">not minority</td>
<td align="left">female</td>
<td align="left">english</td>
<td align="right">33</td>
<td align="left">tenure track</td>
</tr>
</tbody>
</table>
<p>Let’s also use the <code>glimpse()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(evals)</code></pre></div>
<pre><code>Observations: 463
Variables: 7
$ score     &lt;dbl&gt; 4.7, 4.1, 3.9, 4.8, 4.6, 4.3, 2.8, 4.1, 3.4, 4.5, 3.8, 4....
$ bty_avg   &lt;dbl&gt; 5.00, 5.00, 5.00, 5.00, 3.00, 3.00, 3.00, 3.33, 3.33, 3.1...
$ ethnicity &lt;chr&gt; &quot;minority&quot;, &quot;minority&quot;, &quot;minority&quot;, &quot;minority&quot;, &quot;not mino...
$ gender    &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;...
$ language  &lt;chr&gt; &quot;english&quot;, &quot;english&quot;, &quot;english&quot;, &quot;english&quot;, &quot;english&quot;, &quot;e...
$ age       &lt;int&gt; 36, 36, 36, 36, 59, 59, 59, 51, 51, 40, 40, 40, 40, 40, 4...
$ rank      &lt;chr&gt; &quot;tenure track&quot;, &quot;tenure track&quot;, &quot;tenure track&quot;, &quot;tenure t...</code></pre>
<p>We see that both variables of interest, <code>bty_avg</code> and <code>score</code>, consist of numerical values, as well as the <code>age</code> variable. The variables <code>ethnicity</code>, <code>gender</code>, <code>language</code>, and <code>rank</code> however are categorical. Let’s now compute some summary statistics for both the explanatory/predictor variable and the outcome variable using the <code>summary()</code> function, which returns the minimum, the first quartile, the median, the mean AKA the average, the third quartile, and the maximum.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(evals<span class="op">$</span>bty_avg)</code></pre></div>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.67    3.17    4.33    4.42    5.50    8.17 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(evals<span class="op">$</span>score)</code></pre></div>
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   2.30    3.80    4.30    4.17    4.60    5.00 </code></pre>
<p>We get an idea of how the values in both variables distributed. For example, the average teaching score was 4.17 out of 5 whereas beauty scores range from 1.67 to 8.17. The <code>summary()</code> function however only returns what are called <em>univariate</em> summaries i.e. summaries about single variables. Since we are considering the relationship between two numerical variables, it would be nice to have a summary statistic that simultaneously considers both variables. The correlation coefficient is a <em>bivariate</em> summary statistic that fits this bill. It is a value between -1 and 1 that summarizes the <em>strength of the linear relationship between two numerical variables</em>; for more discussion on the correlation coefficient, see Section <a href="2-regression.html#correlationcoefficient">2.8.1</a> below. The correlation coefficient is computed using the <code>cor()</code> function, and in our case, the correlation is positive.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(evals<span class="op">$</span>score, evals<span class="op">$</span>bty_avg)</code></pre></div>
<pre><code>[1] 0.187</code></pre>
<p>Since both the <code>score</code> and <code>bty_avg</code> variables are numerical, a scatterplot is an appropriate graph to visualize this data. Let’s do this using <code>geom_point()</code> and set informative axes labels and title.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals, <span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Relationship of teaching and beauty scores&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxplot1"></span>
<img src="ismaykim_files/figure-html/numxplot1-1.png" alt="Instructor evaluation scores at UT Austin" width="\textwidth" />
<p class="caption">
Figure 2.1: Instructor evaluation scores at UT Austin
</p>
</div>
<p>However Figure <a href="2-regression.html#fig:numxplot1">2.1</a> suffers from <em>overplotting</em>; let’s break it up with a little random jitter added to the points in Figure <a href="2-regression.html#fig:numxplot2">2.2</a>; note that we are only altering the visualization of the points; the original data stays the same.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals, <span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Relationship of teaching and beauty scores&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxplot2"></span>
<img src="ismaykim_files/figure-html/numxplot2-1.png" alt="Instructor evaluation scores at UT Austin: Jittered" width="\textwidth" />
<p class="caption">
Figure 2.2: Instructor evaluation scores at UT Austin: Jittered
</p>
</div>
<p>From this visualization we make several observations:</p>
<ol style="list-style-type: decimal">
<li>Most beauty scores lie between 2 and 8</li>
<li>Most teaching scores lie between 3 and 5</li>
<li>Most importantly, there seems to be a slight positive relationship between teaching score and beauty score, meaning as instructors have higher beauty scores, they tend to have higher teaching scores as well!</li>
</ol>
<p>Let’s first improve on Figure <a href="2-regression.html#fig:numxplot2">2.2</a> by adding the “best-fitting” line in Figure <a href="2-regression.html#fig:numxplot3">2.3</a>; this is easily done by adding a new layer to the plot <code>+ geom_smooth(method=&quot;lm&quot;)</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals, <span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Relationship of teaching and beauty scores&quot;</span>) <span class="op">+</span><span class="st">  </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxplot3"></span>
<img src="ismaykim_files/figure-html/numxplot3-1.png" alt="Simple linear regression line with error band" width="\textwidth" />
<p class="caption">
Figure 2.3: Simple linear regression line with error band
</p>
</div>
<p>The positive slope of the blue line is consistent with our observation from earlier that there is a positive relationship between <code>score</code> and <code>bty_avg</code>. What do we mean by “best-fitting” line? While the intuition is easy to visualize in the above plot, there is a mathematically precise definition of “best”, which we discuss in Section <a href="2-regression.html#leastsquares">2.8.2</a> below.</p>
<p>What are the grey bands surrounding the blue line? These are <em>standard error</em> bands, which can be thought of as error/uncertainty bands. We’ll revisit this concept later so let’s suppress these grey bars for now by adding the argument <code>se=FALSE</code> to <code>geom_smooth(method = &quot;lm&quot;)</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals, <span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Relationship of teaching and beauty scores&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxplot4"></span>
<img src="ismaykim_files/figure-html/numxplot4-1.png" alt="Simple linear regression line without error bands" width="\textwidth" />
<p class="caption">
Figure 2.4: Simple linear regression line without error bands
</p>
</div>
</div>
<div id="model1table" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Simple linear regression</h3>
<p>Need to describe what simple linear regression is.</p>
<p>In order to define a line like the one in Figure <a href="2-regression.html#fig:numxplot4">2.4</a>, we need two quantities called <em>coefficients</em>: an intercept coefficient (the value of <span class="math inline">\(y\)</span> at <span class="math inline">\(x=0\)</span>) and a slope coefficient. What are the intercept and slope coefficients of the above blue best fitting simple linear regression line? Let’s get these values by outputting something called the <em>linear regression table</em> using the <code>get_regression_table()</code> function that we’ve included in the <code>moderndive</code> R package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_regression_table</span>(score <span class="op">~</span><span class="st"> </span>bty_avg, <span class="dt">data =</span> evals)</code></pre></div>
<table>
<caption><span id="tab:numxplot4b">Table 2.2: </span>Linear regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">3.880</td>
<td align="right">0.076</td>
<td align="right">50.96</td>
<td align="right">0</td>
<td align="right">3.731</td>
<td align="right">4.030</td>
</tr>
<tr class="even">
<td align="left">bty_avg</td>
<td align="right">0.067</td>
<td align="right">0.016</td>
<td align="right">4.09</td>
<td align="right">0</td>
<td align="right">0.035</td>
<td align="right">0.099</td>
</tr>
</tbody>
</table>
<p>Let’s consider the inputs to this function first. This function always has form <code>get_regression_table(y~x, data, digits = 3, print = FALSE)</code>:</p>
<ol style="list-style-type: decimal">
<li><code>y ~ x</code> is a “formula” input that tells R to fit a simple linear regression of the outcome variable <code>y</code> as a function of <code>x</code>. Above since we are interested in explaining <code>score</code> as a function of <code>bty_avg</code>, we input <code>score ~ bty_avg</code>. Be very careful to always put the outcome variable before the tilde.</li>
<li><code>data</code> is the data frame that contains the variables <code>y</code> and <code>x</code>. In the above case, we set <code>data = evals</code></li>
<li><code>digits</code> specifies the digits of precision we want the regression table to have. <code>digits</code> defaults to 3, in other words, if you don’t specify this argument, <code>digits = 3</code> is used by default.</li>
<li><code>print</code> is a <code>TRUE</code>/<code>FALSE</code> Boolean value that sets whether or not the output should be printed in Markdown table format, suitable for use in R markdown</li>
</ol>
<p>Now let’s consider the output regression, which has two rows denoted by the first column <code>term</code>: one corresponding to the intercept <span class="math inline">\(b_0\)</span> and one corresponding to the slope <span class="math inline">\(b_{\text{bty_avg}}\)</span> <code>bty_avg</code>. The second column <code>estimate</code> gives us the fitted values for both these values, thus in Figure <a href="2-regression.html#fig:numxplot4">2.4</a> the intercept is 3.88, meaning for an instructor that had a beauty score of <span class="math inline">\(x=0\)</span>, they had on average a teaching score of 3.88. In this case however, while the intercept has a mathematical interpretation, there is no practical interpretation no instructors had anywhere near a beauty score of 0. Furthermore, since <code>score</code> is an average of a panel of 6 students’ ratings from 1 to 10, a <code>bty_avg</code> of 0 would be impossible.</p>
<p>More interestingly is the slope associated with <code>bty_avg</code> of 0.067. The interpretation is: for every increase of 1 in <code>bty_avg</code>, there is an <em>associated</em> increase of <em>on average</em> 0.067 units of <code>score</code>. We note in particular that the sign of this slope is positive, again suggestive of a positive relationship between beauty scores and teaching scores. We are very careful with our wording:</p>
<ul>
<li>We say there is an <em>associated</em> increase, to be cautious not to imply causation.</li>
<li>We say that this associated increase is <em>on average</em> 0.067 units of <code>score</code> because this increase isn’t always exactly 0.067 as we can see in Figure <a href="2-regression.html#fig:numxplot4">2.4</a>, but rather the average associated increase.</li>
</ul>
<p>But what about the remaining 5 columns? We’ll revisit these when we cover <em>inference for regression</em> after you’ve covered Chapter <a href="#hypo"><strong>??</strong></a> where you learn about <em>hypothesis testing</em> and Chapter <a href="#ci"><strong>??</strong></a> where you’ll learn about <em>confidence intervals</em>. For now, we’ll only focus on the <code>term</code> and <code>estimate</code> columns.</p>
<p>We’ve included the <code>get_regression_table()</code> in the <code>moderndive</code> package to make generating clean regression tables easy, and thus have hidden a lot of details from you. If you are curious to know what is going on under the hood of this function, see Section <a href="2-regression.html#underthehood">2.8.3</a> below.</p>
</div>
<div id="model1points" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Observed/fitted values and residuals</h3>
<p>We just saw how to get the value of the intercept and the slope of the regression line from the regression table generated by <code>get_regression_table()</code>. Now instead, say we want information on individual points, in this case one of the <code>n=463</code> instructors in this dataset, one corresponding to each row of <code>evals</code>. For example, say we are interested in the 21st instructor in this dataset:</p>
<table>
<caption><span id="tab:unnamed-chunk-11">Table 2.3: </span>Data for 21st instructor</caption>
<thead>
<tr class="header">
<th align="right">score</th>
<th align="right">bty_avg</th>
<th align="left">ethnicity</th>
<th align="left">gender</th>
<th align="left">language</th>
<th align="right">age</th>
<th align="left">rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4.9</td>
<td align="right">7.33</td>
<td align="left">not minority</td>
<td align="left">female</td>
<td align="left">english</td>
<td align="right">31</td>
<td align="left">tenure track</td>
</tr>
</tbody>
</table>
<p>What is the value on the blue line corresponding to this instructors <code>bty_avg</code> of 7.333? In Figure <a href="2-regression.html#fig:numxplot5">2.5</a> we mark three values in particular corresponding to this instructor:</p>
<ul>
<li>The red circle corresponds to the <em>observed value</em> <span class="math inline">\(y\)</span> = 4.9 and corresponds to this instructors’ observed teaching score.</li>
<li>The red square corresponds to the <em>fitted value</em> <span class="math inline">\(\widehat{y}\)</span> = 4.369 and corresponds to the value on the regression line for <span class="math inline">\(x = 7.333\)</span>. We compute this value using the intercept and slope in the regression table above: <span class="math inline">\(\widehat{y} = b_0 + b_1 x = 3.88 + 0.067 \times 7.333 = 4.369\)</span></li>
<li>The length of the blue arrow is the <em>residual</em> $y -  = 4.9 - 4.369 = 0.531. The residual can be thought of as the error/lack-of-fit for this particular point. So the bigger the residual, the less the fitted value <span class="math inline">\(\widehat{y}\)</span> matches up with the observed value <span class="math inline">\(y\)</span>.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:numxplot5"></span>
<img src="ismaykim_files/figure-html/numxplot5-1.png" alt="Example of observed value, fitted value, and residual" width="\textwidth" />
<p class="caption">
Figure 2.5: Example of observed value, fitted value, and residual
</p>
</div>
<p>What if we want both</p>
<ol style="list-style-type: decimal">
<li>the fitted value <span class="math inline">\(\widehat{y} = b_0 + b_1 \times x\)</span></li>
<li>the residual <span class="math inline">\(y - \widehat{y}\)</span></li>
</ol>
<p>not only the 21st instructor but</p>
<ul>
<li>for all 463 instructors in the study, in other words</li>
<li>for all 463 rows in the <code>evals</code> data frame, in other words</li>
<li>for all 463 points in regression plot in Figure <a href="2-regression.html#fig:numxplot4">2.4</a>?</li>
</ul>
<p>We could repeat the above calculations 463 times, but that would be tedious and time consuming. Instead, let’s use the <code>get_regression_points()</code> function that we’ve included in the <code>moderndive</code> R package. Note that in the table below we only present the results for 5 arbitrarily chosen rows out of 463.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(score <span class="op">~</span><span class="st"> </span>bty_avg, <span class="dt">data =</span> evals)
regression_points</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-13">Table 2.4: </span>Regression points (5 arbitrarily chosen rows out of 463)</caption>
<thead>
<tr class="header">
<th align="right">score</th>
<th align="right">bty_avg</th>
<th align="right">score_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4.9</td>
<td align="right">7.33</td>
<td align="right">4.37</td>
<td align="right">0.531</td>
</tr>
<tr class="even">
<td align="right">3.6</td>
<td align="right">6.67</td>
<td align="right">4.33</td>
<td align="right">-0.725</td>
</tr>
<tr class="odd">
<td align="right">4.9</td>
<td align="right">3.50</td>
<td align="right">4.11</td>
<td align="right">0.786</td>
</tr>
<tr class="even">
<td align="right">3.3</td>
<td align="right">2.33</td>
<td align="right">4.04</td>
<td align="right">-0.736</td>
</tr>
<tr class="odd">
<td align="right">4.4</td>
<td align="right">4.67</td>
<td align="right">4.19</td>
<td align="right">0.209</td>
</tr>
</tbody>
</table>
<p>Just as with the <code>get_regression_table()</code> function, the inputs to the <code>get_regression_points()</code> function are the same, however the outputs are different. Let’s inspect the individual columns:</p>
<ul>
<li>The <code>score</code> column represents the observed value of the outcome variable <span class="math inline">\(y\)</span></li>
<li>The <code>bty_avg</code> column represents the values of the explanatory/predictor variable <span class="math inline">\(x\)</span></li>
<li>The <code>score_hat</code> column represents the fitted values <span class="math inline">\(\widehat{y}\)</span></li>
<li>The <code>residual</code> column represents the residuals <span class="math inline">\(y - \widehat{y}\)</span></li>
</ul>
<p>The prove to ourselves that the results make sense, let’s manually replicate the internal computation that <code>get_regression_points()</code> performs using the <code>mutate()</code> verb from Chapter <a href="#wrangling"><strong>??</strong></a></p>
<ol style="list-style-type: decimal">
<li>First we compute a duplicate of the fitted values <span class="math inline">\(\widehat{y} = b_0 + b_1 \times x\)</span> where the intercept <span class="math inline">\(b_0\)</span> = 3.88 and the slope <span class="math inline">\(b_1\)</span> = 0.067 and store these in <code>score_hat_2</code></li>
<li>Then we compute the a duplicated the residuals <span class="math inline">\(y - \widehat{y}\)</span> and store these in <code>residual_2</code></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span>regression_points <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">score_hat_2 =</span> <span class="fl">3.880</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.067</span> <span class="op">*</span><span class="st"> </span>bty_avg) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">residual_2 =</span> score <span class="op">-</span><span class="st"> </span>score_hat_<span class="dv">2</span>)
regression_points</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-15">Table 2.5: </span>Regression points (5 arbitrarily chosen rows out of 463)</caption>
<thead>
<tr class="header">
<th align="right">score</th>
<th align="right">bty_avg</th>
<th align="right">score_hat</th>
<th align="right">residual</th>
<th align="right">score_hat_2</th>
<th align="right">residual_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4.9</td>
<td align="right">7.33</td>
<td align="right">4.37</td>
<td align="right">0.531</td>
<td align="right">4.37</td>
<td align="right">0.529</td>
</tr>
<tr class="even">
<td align="right">3.6</td>
<td align="right">6.67</td>
<td align="right">4.33</td>
<td align="right">-0.725</td>
<td align="right">4.33</td>
<td align="right">-0.727</td>
</tr>
<tr class="odd">
<td align="right">4.9</td>
<td align="right">3.50</td>
<td align="right">4.11</td>
<td align="right">0.786</td>
<td align="right">4.11</td>
<td align="right">0.786</td>
</tr>
<tr class="even">
<td align="right">3.3</td>
<td align="right">2.33</td>
<td align="right">4.04</td>
<td align="right">-0.736</td>
<td align="right">4.04</td>
<td align="right">-0.736</td>
</tr>
<tr class="odd">
<td align="right">4.4</td>
<td align="right">4.67</td>
<td align="right">4.19</td>
<td align="right">0.209</td>
<td align="right">4.19</td>
<td align="right">0.207</td>
</tr>
</tbody>
</table>
<p>We see that our manually computed variables <code>score_hat_2</code> and <code>residual_2</code> equal the original results (up to rounding error).</p>
</div>
<div id="model1residuals" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Residual analysis</h3>
<p>Recall the residuals can be thought of the error or the “lack-of-fit” between the observed value <span class="math inline">\(y\)</span> and the fitted value <span class="math inline">\(\widehat{y}\)</span> on the blue regression line in Figure <a href="2-regression.html#fig:numxplot4">2.4</a>. Ideally when we fit a regression model, we’d like there to be <em>no systematic pattern</em> to these residuals. In other words, the error is seemingly random. What does this mean?</p>
<ol style="list-style-type: decimal">
<li>The residuals should be on average 0. In other words, sometimes we’ll make a positive error, sometimes we’ll make a negative error, but on average the error is 0.</li>
<li>The spread of the residuals should be consistent.</li>
<li>The value of the residuals should not depend on the value of x. If it did, then the errors would not be seemingly random.</li>
</ol>
<p>Investigating any such patterns is known as <em>residual analysis</em>. Let’s perform our residual analysis in two ways. First, recall in Figure <a href="2-regression.html#fig:numxplot5">2.5</a> above we plotted:</p>
<ul>
<li>On the y-axis: <span class="math inline">\(y\)</span> teaching score</li>
<li>On the x-axis: <span class="math inline">\(x\)</span> beauty score</li>
<li>Blue arrow: one example of a residual</li>
</ul>
<p>Instead, in Figure <a href="2-regression.html#fig:numxplot6">2.6</a> below let’s plot</p>
<ul>
<li>On the y-axis: the residual <span class="math inline">\(y-\widehat{y}\)</span> instead</li>
<li>On the x-axis: <span class="math inline">\(x\)</span> beauty score (same as before)</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:numxplot6"></span>
<img src="ismaykim_files/figure-html/numxplot6-1.png" alt="Plot of residuals over beauty score" width="\textwidth" />
<p class="caption">
Figure 2.6: Plot of residuals over beauty score
</p>
</div>
<p>You can think of Figure <a href="2-regression.html#fig:numxplot6">2.6</a> as Figure <a href="2-regression.html#fig:numxplot5">2.5</a>, but with the blue line flattened out. Does it seem like there is <em>no systematic pattern</em> to the residuals? This question is rather qualitative and subjective in nature, thus different people may respond different. However, it can be argued that there isn’t a <em>drastic</em> pattern in the residuals.</p>
<p>Here are some hypothetical examples where there are <em>drastic</em> patterns to the residuals:</p>
<div class="figure" style="text-align: center"><span id="fig:numxplot7"></span>
<img src="ismaykim_files/figure-html/numxplot7-1.png" alt="Examples of less than ideal residual patterns" width="\textwidth" />
<p class="caption">
Figure 2.7: Examples of less than ideal residual patterns
</p>
</div>
<p>The second way to look at the residuals is using a histogram:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.25</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Residual&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/model1_residuals_hist-1.png" alt="Histogram of residuals" width="\textwidth" />
<p class="caption">
(#fig:model1_residuals_hist)Histogram of residuals
</p>
</div>
<p>This histogram seems to indicate that we have more positive residuals than negative. Since residual = <span class="math inline">\(y-\widehat{y} &gt; 0\)</span> when <span class="math inline">\(y &gt; \widehat{y}\)</span>, it seems our fitted teaching score from the regression model tend to <em>underestimate</em> the true teaching score. This histogram has a slight <em>left-skew</em> in that there is a long tail on the left. Another way to say this is this data exhibit a <em>negative skew</em>. Here are examples of an ideal and less than ideal patterns of residuals.</p>
<div class="figure" style="text-align: center"><span id="fig:numxplot9"></span>
<img src="ismaykim_files/figure-html/numxplot9-1.png" alt="Examples of ideal and less than ideal residual patterns" width="\textwidth" />
<p class="caption">
Figure 2.8: Examples of ideal and less than ideal residual patterns
</p>
</div>
<p>In fact, we’ll see later on that we would like the residuals to be <em>normally distributed</em> with mean 0. In other words, be bell-shaped and centered at 0! While this requirement and residual analysis in general may some of you as not being overly critical at this point, we’ll see later after we’ve covered <em>statistical inference</em> that for the last five columns of the regression table from earlier (std error, statistic, p-value, conf low, and conf high) to have valid interpretations, the above three conditions should roughly hold. More on this in Section .</p>
</div>
<div id="your-turn" class="section level3">
<h3><span class="header-section-number">2.2.5</span> Your Turn</h3>
<p>Repeat the above analysis where teaching <code>score</code> is the outcome variable, but now use <code>age</code> as the explanatory/predictor variable. Recall the steps:</p>
<ol style="list-style-type: decimal">
<li>Perform an exploratory data analysis by
<ol style="list-style-type: lower-alpha">
<li>Looking at the raw values</li>
<li>Computing summary statistics of the variables of interest</li>
<li>Creating informative visualizations</li>
</ol></li>
<li>Fit a linear regression model and get information about the “best-fitting” line from the regression table by using the <code>get_regression_table()</code> function</li>
<li>Get information on all <span class="math inline">\(n\)</span> data points AKA all <span class="math inline">\(n\)</span> rows in the dataset AKA all instructors, in particular the fitted values and the residuals, using the <code>get_regression_points()</code> function.</li>
<li>Perform a residual analysis and look for any systematic patterns in the residuals. Ideally, there should be little to no pattern.</li>
</ol>
</div>
</div>
<div id="model2" class="section level2">
<h2><span class="header-section-number">2.3</span> 5RM#2: Life Expectancy</h2>
<p>It’s an unfortunate truth that life expectancy is not the same across various countries in the world; there are a multitude of factors that are associated with how long people live. International development agencies are very interested in studying these differences in the hope of understanding where governments should allocate resources to address this problem. One way to compare differences in life expectancy is between continents: “Do countries in certain continents have higher life expectancy?” or “Do certain continents have a lot of variation in life expectancy?”</p>
<p>To this end, let’s study the <code>gapminder</code> data frame in the <code>gapminder</code> package. Recall we introduced this dataset in Chapter <a href="#gapminder"><strong>??</strong></a> when we first studied the “Grammar of Graphics”; in particular Figure <a href="#fig:gapminder"><strong>??</strong></a>. This dataset has development data about various countries for 5-year intervals between 1952 and 2007. Let’s have</p>
<ul>
<li>Outcome variable <span class="math inline">\(y\)</span>: Mean life expectancy in 2007 for <span class="math inline">\(n=142\)</span> countries</li>
<li>Explanatory variables <span class="math inline">\(x\)</span>
<ul>
<li>continent</li>
<li>GDP per capita</li>
</ul></li>
</ul>
<p>Let’s load the <code>gapminder</code> data, <code>filter()</code> for only observations in 2007, <code>select()</code> only a subset of the variables, and save this in a data frame <code>gapminder2007</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gapminder)
gapminder2007 &lt;-<span class="st"> </span>gapminder <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2007</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(country, continent, lifeExp, gdpPercap)</code></pre></div>
<p>In this section we’ll try to explain between country differences in life expectancy as a function of which continent the country is located in. We’ll model the relationship between these two variables with linear regression again, but note that our explanatory/predictor variable <span class="math inline">\(x\)</span> is now categorical, and not numerical like when we covered simple linear regression in Section <a href="2-regression.html#model1">2.2</a>:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, in this case <code>lifeExp</code></li>
<li>A single numerical explanatory/predictor variable <span class="math inline">\(x\)</span>, in this case <code>continent</code></li>
</ol>
<p>The concept of a “best-fitting” line is a little different when the explanatory/predictor variable <span class="math inline">\(x\)</span> is numerical; we’ll study these differences shortly.</p>
<div id="model2EDA" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Exploratory data analysis</h3>
<p>Let’s look at the raw data values both by bringing up RStudio’s spreadsheet viewer, although in Table <a href="2-regression.html#tab:model2-data-preview">2.6</a> we only show 5 randomly selected countries out of 142, and using the <code>glimpse()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(gapminder2007)</code></pre></div>
<table>
<caption><span id="tab:model2-data-preview">Table 2.6: </span>Random sample of 5 countries</caption>
<thead>
<tr class="header">
<th align="left">country</th>
<th align="left">continent</th>
<th align="right">lifeExp</th>
<th align="right">gdpPercap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Netherlands</td>
<td align="left">Europe</td>
<td align="right">79.8</td>
<td align="right">36798</td>
</tr>
<tr class="even">
<td align="left">Paraguay</td>
<td align="left">Americas</td>
<td align="right">71.8</td>
<td align="right">4173</td>
</tr>
<tr class="odd">
<td align="left">Burundi</td>
<td align="left">Africa</td>
<td align="right">49.6</td>
<td align="right">430</td>
</tr>
<tr class="even">
<td align="left">Tanzania</td>
<td align="left">Africa</td>
<td align="right">52.5</td>
<td align="right">1107</td>
</tr>
<tr class="odd">
<td align="left">Venezuela</td>
<td align="left">Americas</td>
<td align="right">73.7</td>
<td align="right">11416</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(gapminder2007)</code></pre></div>
<pre><code>Observations: 142
Variables: 4
$ country   &lt;fctr&gt; Afghanistan, Albania, Algeria, Angola, Argentina, Austra...
$ continent &lt;fctr&gt; Asia, Europe, Africa, Africa, Americas, Oceania, Europe,...
$ lifeExp   &lt;dbl&gt; 43.8, 76.4, 72.3, 42.7, 75.3, 81.2, 79.8, 75.6, 64.1, 79....
$ gdpPercap &lt;dbl&gt; 975, 5937, 6223, 4797, 12779, 34435, 36126, 29796, 1391, ...</code></pre>
<p>We see that the variable <code>continent</code> is indeed categorical, as it is encoded as <code>fctr</code> which stands for “factor”: R’s way of storing categorical variables. Let’s look at a summary of the explanatory/predictor variable <code>continent</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(gapminder2007<span class="op">$</span>continent)</code></pre></div>
<pre><code>  Africa Americas     Asia   Europe  Oceania 
      52       25       33       30        2 </code></pre>
<p>We observe that all continents have 25 countries or more, but Oceania only has two: Australia and New Zealand. Let’s now compute some summary statistics of the outcome variable <code>lifeExp</code>, in particular the worldwide median and mean life expectancy</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lifeExp_worldwide &lt;-<span class="st"> </span>gapminder2007 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">median =</span> <span class="kw">median</span>(lifeExp), <span class="dt">mean =</span> <span class="kw">mean</span>(lifeExp))</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-21">Table 2.7: </span>Worldwide life expectancy</caption>
<thead>
<tr class="header">
<th align="right">median</th>
<th align="right">mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">71.9</td>
<td align="right">67</td>
</tr>
</tbody>
</table>
<p>Worldwide roughly half the countries had life expectancies of 71.935 years or less, while roughly half were higher. The mean however is lower at 67.007. Why are these two values different? Let’s look at a histogram of <code>lifeExp</code> to see why.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(gapminder2007, <span class="kw">aes</span>(<span class="dt">x =</span> lifeExp)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Life expectancy&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of countries&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Worldwide life expectancy&quot;</span>)</code></pre></div>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-22-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We say that this data is <em>left-skewed</em>: there are a few countries with very low life expectancies that are bringing down the mean life expectancy. However, the median is less sensitive to the effects of such outliers. Hence the median is greater than the mean in this case. Let’s proceed by comparing median and mean life expectancy between continents by adding a <code>group_by(continent)</code> to the above code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lifeExp_by_continent &lt;-<span class="st"> </span>gapminder2007 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(continent) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">median =</span> <span class="kw">median</span>(lifeExp), <span class="dt">mean =</span> <span class="kw">mean</span>(lifeExp))</code></pre></div>
<table>
<caption><span id="tab:catxplot0">Table 2.8: </span>Life expectancy by continent</caption>
<thead>
<tr class="header">
<th align="left">continent</th>
<th align="right">median</th>
<th align="right">mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Africa</td>
<td align="right">52.9</td>
<td align="right">54.8</td>
</tr>
<tr class="even">
<td align="left">Americas</td>
<td align="right">72.9</td>
<td align="right">73.6</td>
</tr>
<tr class="odd">
<td align="left">Asia</td>
<td align="right">72.4</td>
<td align="right">70.7</td>
</tr>
<tr class="even">
<td align="left">Europe</td>
<td align="right">78.6</td>
<td align="right">77.6</td>
</tr>
<tr class="odd">
<td align="left">Oceania</td>
<td align="right">80.7</td>
<td align="right">80.7</td>
</tr>
</tbody>
</table>
<p>We now that there are differences in life expectancies between the continents. For example, while the median life expectancy across all <span class="math inline">\(n = 142\)</span> countries in 2007 was 71.935, the median life expectancy across only the <span class="math inline">\(n =52\)</span> countries in Africa was only 52.927.</p>
<p>Let’s create an appropriate visualization. One way to compare the life expectancies of countries in different continents would be via a faceted histogram:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(gapminder2007, <span class="kw">aes</span>(<span class="dt">x =</span> lifeExp)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Life expectancy&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of countries&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Life expectancy by continent&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>continent, <span class="dt">nrow =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:catxplot0b"></span>
<img src="ismaykim_files/figure-html/catxplot0b-1.png" alt="Life expectancy in 2007" width="\textwidth" />
<p class="caption">
Figure 2.9: Life expectancy in 2007
</p>
</div>
<p>Another way would be via a boxplot, which is well suited for visualizing one numerical and one categorical variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(gapminder2007, <span class="kw">aes</span>(<span class="dt">x =</span> continent, <span class="dt">y =</span> lifeExp)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Continent&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Life expectancy (years)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Life expectancy by continent&quot;</span>) </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:catxplot1"></span>
<img src="ismaykim_files/figure-html/catxplot1-1.png" alt="Life expectancy in 2007" width="\textwidth" />
<p class="caption">
Figure 2.10: Life expectancy in 2007
</p>
</div>
<p>We can now easily compare life expectancies between continents with single horizontal lines. Something that people new to boxplots forget is that the solid bars in the middle of the boxes correspond to <strong>medians and not means</strong>. Let’s modify this plot in two ways. First, let’s treat the median life expectancy years for Africa of 52.927 as a <em>baseline for comparison</em> are mark this value on the y-axis with a horizontal line via <code>geom_hline()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(gapminder2007, <span class="kw">aes</span>(<span class="dt">x =</span> continent, <span class="dt">y =</span> lifeExp)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Continent&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Life expectancy (years)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Life expectancy by continent&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="fl">52.93</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:catxplot1b"></span>
<img src="ismaykim_files/figure-html/catxplot1b-1.png" alt="Life expectancy in 2007" width="\textwidth" />
<p class="caption">
Figure 2.11: Life expectancy in 2007
</p>
</div>
<p>Second, let’s recenter the y-axis at Africa’s median life expectancy by subtracting 52.927 from all values. This allows us to focus on relative differences from Africa’s median life expectancy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(gapminder2007, <span class="kw">aes</span>(<span class="dt">x =</span> continent, <span class="dt">y =</span> lifeExp <span class="op">-</span><span class="st"> </span><span class="fl">52.93</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="fl">52.93</span> <span class="op">-</span><span class="st"> </span><span class="fl">52.93</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Continent&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Difference in life expectancy vs Africa (years)&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Life expectancy relative to Africa&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:catxplot2"></span>
<img src="ismaykim_files/figure-html/catxplot2-1.png" alt="Difference in life expectancy relative to African median of 52.93 years" width="\textwidth" />
<p class="caption">
Figure 2.12: Difference in life expectancy relative to African median of 52.93 years
</p>
</div>
<p>Using the “eyeball test”, we make the following observations:</p>
<ul>
<li>Differences in median life expectancy vs. the baseline for comparison, Africa’s median life expectancy of 52.927 years:
<ol style="list-style-type: decimal">
<li>The median life expectancy of the Americas is roughly 20 years greater.</li>
<li>The median life expectancy of Asia is roughly 20 years greater.</li>
<li>The median life expectancy of Europe is roughly 25 years greater.</li>
<li>The median life expectancy of Oceania is roughly 27.8 years greater.</li>
</ol></li>
<li>Africa and Asia have much more spread/variation in life expectancy as indicated by the interquartile range (the height of the boxes).</li>
<li>Oceania has almost no spread/variation, but this might in large part be due to the fact there are only two countries in Oceania.</li>
</ul>
</div>
<div id="model2table" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Linear regression</h3>
<p>In Section <a href="2-regression.html#model1table">2.2.2</a> we introduced <em>simple</em> linear regression, which involves modeling the relationship between a numerical outcome variable <span class="math inline">\(y\)</span> as a function of a numerical explanatory/predictor variable <span class="math inline">\(x\)</span>, in our life expectancy example, we now have a categorical explanatory/predictor variable <span class="math inline">\(x\)</span> <code>continent</code>. While we still can fit a regression model, given our categorical explanatory/predictor variable we no longer have a concept of a “best-fitting” line, but differences relative to a baseline for comparison.</p>
<p>Before we fit our regression model, let’s create a table similar to Table <a href="2-regression.html#tab:catxplot0">2.8</a>, but</p>
<ol style="list-style-type: decimal">
<li>Report the mean life expectancy for each continent.</li>
<li>Report the difference in mean life expectancy <em>relative</em> to Africa’s mean life expectancy of 54.806 in the column “mean vs Africa”; this column is simple the “mean” column minus 54.806.</li>
</ol>
<p>Think back to your observations from the eye-ball test of Figure <a href="2-regression.html#fig:catxplot2">2.12</a> at the end of the last section. The column “mean vs Africa” is the same idea of comparing a summary statistic to a baseline for comparison, in this case the countries of Africa, but using means instead of medians.</p>
<table>
<caption><span id="tab:continent-mean-life-expectancies">Table 2.9: </span>Mean life expectancy by continent</caption>
<thead>
<tr class="header">
<th align="left">continent</th>
<th align="right">mean</th>
<th align="right">mean vs Africa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Africa</td>
<td align="right">54.8</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">Americas</td>
<td align="right">73.6</td>
<td align="right">18.8</td>
</tr>
<tr class="odd">
<td align="left">Asia</td>
<td align="right">70.7</td>
<td align="right">15.9</td>
</tr>
<tr class="even">
<td align="left">Europe</td>
<td align="right">77.6</td>
<td align="right">22.8</td>
</tr>
<tr class="odd">
<td align="left">Oceania</td>
<td align="right">80.7</td>
<td align="right">25.9</td>
</tr>
</tbody>
</table>
<p>Now, let’s use the <code>get_regression_table()</code> function we introduced in Section <a href="2-regression.html#model1table">2.2.2</a> to obtain the <em>regression table</em> for <code>gapminder2007</code> analysis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_regression_table</span>(lifeExp <span class="op">~</span><span class="st"> </span>continent, <span class="dt">data =</span> gapminder2007)</code></pre></div>
<table>
<caption><span id="tab:catxplot4b">Table 2.10: </span>Linear regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">54.8</td>
<td align="right">1.02</td>
<td align="right">53.45</td>
<td align="right">0</td>
<td align="right">52.8</td>
<td align="right">56.8</td>
</tr>
<tr class="even">
<td align="left">continentAmericas</td>
<td align="right">18.8</td>
<td align="right">1.80</td>
<td align="right">10.45</td>
<td align="right">0</td>
<td align="right">15.2</td>
<td align="right">22.4</td>
</tr>
<tr class="odd">
<td align="left">continentAsia</td>
<td align="right">15.9</td>
<td align="right">1.65</td>
<td align="right">9.68</td>
<td align="right">0</td>
<td align="right">12.7</td>
<td align="right">19.2</td>
</tr>
<tr class="even">
<td align="left">continentEurope</td>
<td align="right">22.8</td>
<td align="right">1.70</td>
<td align="right">13.47</td>
<td align="right">0</td>
<td align="right">19.5</td>
<td align="right">26.2</td>
</tr>
<tr class="odd">
<td align="left">continentOceania</td>
<td align="right">25.9</td>
<td align="right">5.33</td>
<td align="right">4.86</td>
<td align="right">0</td>
<td align="right">15.4</td>
<td align="right">36.5</td>
</tr>
</tbody>
</table>
<p>Just as before, we have the <code>term</code> and <code>estimates</code> columns of interest, but unlike before, we now have 5 rows corresponding to 5 outputs in our table: an intercept like before, but also <code>continentAmericas</code>, <code>continentAsia</code>, <code>continentEurope</code>, and <code>continentOceania</code>. What are these values?</p>
<ol style="list-style-type: decimal">
<li><code>intercept = 54.8</code> corresponds to the mean life expectancy for Africa. This mean life expectancy is treated as a baseline for comparison for the other continents.</li>
<li><code>continentAmericas = 18.8</code> is the difference in mean life expectancies of the Americas minus Africa. Note that 18.80 = 73.6 - 54.8 is the 2nd “mean vs Africa” value in Table <a href="2-regression.html#tab:continent-mean-life-expectancies">2.9</a>.</li>
<li><code>continentAmericas = 15.9</code> is the difference in mean life expectancy of Asia minus Africa. Note that 15.9 = 70.7 - 54.8 is the 2nd “mean vs Africa” value in Table <a href="2-regression.html#tab:continent-mean-life-expectancies">2.9</a>.</li>
<li><code>continentEurope = 22.8</code> is the difference in mean life expectancy of Europe minus Africa. Note that 22.8 = 77.6 - 54.8 is the 3rd “mean vs Africa” value in Table <a href="2-regression.html#tab:continent-mean-life-expectancies">2.9</a>.</li>
<li><code>continentOceania = 25.9</code> is the difference in mean life expectancy of Oceania minus Africa. Note that 25.9 = 80.7 - 54.8 is the 3rd “mean vs Africa” value in Table <a href="2-regression.html#tab:continent-mean-life-expectancies">2.9</a>.</li>
</ol>
<p>Let’s generalize this idea a bit. If we fit a linear regression model using an explanatory/predictor variable <span class="math inline">\(x\)</span> that has <span class="math inline">\(k\)</span> levels, a regression model will return an intercept and <span class="math inline">\(k-1\)</span> “slope” coefficients of differences in means relative to a baseline mean for comparison. In our case, since there are <span class="math inline">\(k=5\)</span> continents, the regression model returns an intercept corresponding to the baseline for comparison Africa and <span class="math inline">\(k-1=4\)</span> slope coefficients corresponding to the Americas, Asia, Europe, and Oceania. Africa was chosen as the baseline by R for no other reason than it is first alphabetically of the 5 continents. Note you can manually specify which continent to use as baseline, but we leave that to a more advanced course.</p>
</div>
<div id="model2residuals" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Observed/fitted values and residuals</h3>
<p>What do fitted values <span class="math inline">\(\widehat{y}\)</span> and residuals <span class="math inline">\(y - \widehat{y}\)</span> correspond to when the explanatory/predictor variable <span class="math inline">\(x\)</span> is categorical? Let’s investigate these values for the first 10 countries in the <code>gapminder2007</code> dataset:</p>
<table>
<caption><span id="tab:unnamed-chunk-27">Table 2.11: </span>First 10 out of 142 countries</caption>
<thead>
<tr class="header">
<th align="left">country</th>
<th align="left">continent</th>
<th align="right">lifeExp</th>
<th align="right">gdpPercap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Afghanistan</td>
<td align="left">Asia</td>
<td align="right">43.8</td>
<td align="right">975</td>
</tr>
<tr class="even">
<td align="left">Albania</td>
<td align="left">Europe</td>
<td align="right">76.4</td>
<td align="right">5937</td>
</tr>
<tr class="odd">
<td align="left">Algeria</td>
<td align="left">Africa</td>
<td align="right">72.3</td>
<td align="right">6223</td>
</tr>
<tr class="even">
<td align="left">Angola</td>
<td align="left">Africa</td>
<td align="right">42.7</td>
<td align="right">4797</td>
</tr>
<tr class="odd">
<td align="left">Argentina</td>
<td align="left">Americas</td>
<td align="right">75.3</td>
<td align="right">12779</td>
</tr>
<tr class="even">
<td align="left">Australia</td>
<td align="left">Oceania</td>
<td align="right">81.2</td>
<td align="right">34435</td>
</tr>
<tr class="odd">
<td align="left">Austria</td>
<td align="left">Europe</td>
<td align="right">79.8</td>
<td align="right">36126</td>
</tr>
<tr class="even">
<td align="left">Bahrain</td>
<td align="left">Asia</td>
<td align="right">75.6</td>
<td align="right">29796</td>
</tr>
<tr class="odd">
<td align="left">Bangladesh</td>
<td align="left">Asia</td>
<td align="right">64.1</td>
<td align="right">1391</td>
</tr>
<tr class="even">
<td align="left">Belgium</td>
<td align="left">Europe</td>
<td align="right">79.4</td>
<td align="right">33693</td>
</tr>
</tbody>
</table>
<p>Recall the <code>get_regression_points()</code> function we used in Section <a href="2-regression.html#model1points">2.2.3</a> that returns the fitted value and residual for</p>
<ul>
<li>for all 142 countries in our dataset</li>
<li>for all 142 rows in the <code>gapminder2007</code> data frame</li>
<li>for all 142 data points used in the five boxplots in Figure <a href="2-regression.html#fig:catxplot2">2.12</a></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(lifeExp <span class="op">~</span><span class="st"> </span>continent, <span class="dt">data =</span> gapminder2007)
regression_points</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-29">Table 2.12: </span>Regression points (First 10 out of 142 countries)</caption>
<thead>
<tr class="header">
<th align="right">lifeexp</th>
<th align="left">continent</th>
<th align="right">lifeexp_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">43.8</td>
<td align="left">Asia</td>
<td align="right">70.7</td>
<td align="right">-26.900</td>
</tr>
<tr class="even">
<td align="right">76.4</td>
<td align="left">Europe</td>
<td align="right">77.6</td>
<td align="right">-1.226</td>
</tr>
<tr class="odd">
<td align="right">72.3</td>
<td align="left">Africa</td>
<td align="right">54.8</td>
<td align="right">17.495</td>
</tr>
<tr class="even">
<td align="right">42.7</td>
<td align="left">Africa</td>
<td align="right">54.8</td>
<td align="right">-12.075</td>
</tr>
<tr class="odd">
<td align="right">75.3</td>
<td align="left">Americas</td>
<td align="right">73.6</td>
<td align="right">1.712</td>
</tr>
<tr class="even">
<td align="right">81.2</td>
<td align="left">Oceania</td>
<td align="right">80.7</td>
<td align="right">0.515</td>
</tr>
<tr class="odd">
<td align="right">79.8</td>
<td align="left">Europe</td>
<td align="right">77.6</td>
<td align="right">2.180</td>
</tr>
<tr class="even">
<td align="right">75.6</td>
<td align="left">Asia</td>
<td align="right">70.7</td>
<td align="right">4.907</td>
</tr>
<tr class="odd">
<td align="right">64.1</td>
<td align="left">Asia</td>
<td align="right">70.7</td>
<td align="right">-6.666</td>
</tr>
<tr class="even">
<td align="right">79.4</td>
<td align="left">Europe</td>
<td align="right">77.6</td>
<td align="right">1.792</td>
</tr>
</tbody>
</table>
<p>Notice</p>
<ul>
<li>The fitted values <span class="math inline">\(\widehat{\text{lifeexp}}\)</span>. Countries in Africa have the same fitted value of 54.8, which is the mean life expectancy of Africa; countries in Asia have the same fitted value of 70.7, which is the mean life expectancy of Asia; this similarly holds for countries in the Americas, Europe, and Oceania.</li>
<li>The <code>residual</code> column is simply <span class="math inline">\(y - \widehat{y}\)</span> = <code>lifeexp - lifeexp_hat</code>. These values can be interpreted as that particular countries deviation from the mean life expectancy of the respective continent’s mean. For example, the first row of this dataset corresponds to Afghanistan, and the residual of -26.9 = 43.8</li>
<li>70.7 is Afghanistan’s mean life expectancy minus the mean life expectancy of all Asian countries.</li>
</ul>
</div>
<div id="model2residuals" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Residual analysis</h3>
<p>Recall our discussion on residuals from Section <a href="2-regression.html#model1residuals">2.2.4</a> where our goal was to investigate whether or not there was a <em>systematic pattern</em> to the residuals, as ideally since residuals can be thought of as error, there should be no such pattern. While there are many ways to do such residual analysis, we focused on two approaches based on visualizations.</p>
<ol style="list-style-type: decimal">
<li>A plot with residuals on the y-axis and the predictor (in this case continent) on the x-axis</li>
<li>A histogram of all residuals</li>
</ol>
<p>First, let’s plot the residuals vs continent in Figure <a href="2-regression.html#fig:catxplot7">2.13</a>, but also let’s plot all 142 points with a little horizontal random jitter by setting the <code>width = 0.1</code> parameter in <code>geom_jitter()</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> continent, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Continent&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:catxplot7"></span>
<img src="ismaykim_files/figure-html/catxplot7-1.png" alt="Plot of residuals over continent" width="\textwidth" />
<p class="caption">
Figure 2.13: Plot of residuals over continent
</p>
</div>
<p>We observe:</p>
<ol style="list-style-type: decimal">
<li>While not perfectly balanced above and below the line <span class="math inline">\(y=0\)</span>, there seems to be a rough balance of both positive and negative residuals for all 5 continents.</li>
<li>However, there is one clear outlier in Asia. It has the smallest residual, hence also has the smallest life expectancy in Asia.</li>
</ol>
<p>Let’s see investigate the 5 countries in Asia with the shortest life expectancy:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gapminder2007 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(continent <span class="op">==</span><span class="st"> &quot;Asia&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(lifeExp)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-31">Table 2.13: </span>Countries in Asia with shortest life expectancy</caption>
<thead>
<tr class="header">
<th align="left">country</th>
<th align="left">continent</th>
<th align="right">lifeExp</th>
<th align="right">gdpPercap</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Afghanistan</td>
<td align="left">Asia</td>
<td align="right">43.8</td>
<td align="right">975</td>
</tr>
<tr class="even">
<td align="left">Iraq</td>
<td align="left">Asia</td>
<td align="right">59.5</td>
<td align="right">4471</td>
</tr>
<tr class="odd">
<td align="left">Cambodia</td>
<td align="left">Asia</td>
<td align="right">59.7</td>
<td align="right">1714</td>
</tr>
<tr class="even">
<td align="left">Myanmar</td>
<td align="left">Asia</td>
<td align="right">62.1</td>
<td align="right">944</td>
</tr>
<tr class="odd">
<td align="left">Yemen, Rep.</td>
<td align="left">Asia</td>
<td align="right">62.7</td>
<td align="right">2281</td>
</tr>
</tbody>
</table>
<p>This was the earlier identified residual for Afghanistan of -26.9. Unfortunately given recent geopolitical turmoil, individuals who live in Afghanistan have a drastically lower life expectancy.</p>
<p>Second, let’s look at a histogram of all 142 values of residuals in Figure <a href="2-regression.html#fig:catxplot8">2.14</a>. In this case, the residuals form a rather nice bell-shape, although there are a couple of very low and very high values at the tails. As we said previously, searching for patterns in residuals can be somewhat subjective, but ideally we hope there are no “drastic” patterns.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Residual&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:catxplot8"></span>
<img src="ismaykim_files/figure-html/catxplot8-1.png" alt="Histogram of residuals" width="\textwidth" />
<p class="caption">
Figure 2.14: Histogram of residuals
</p>
</div>
</div>
<div id="your-turn-1" class="section level3">
<h3><span class="header-section-number">2.3.5</span> Your turn</h3>
<p>Repeat this same analysis but using GDP per capita <code>gdpPercap</code> as the outcome variable. Recall the four steps we’ve been following:</p>
<ol style="list-style-type: decimal">
<li>Perform an exploratory data analysis</li>
<li>Fit a linear regression model and get information about the model</li>
<li>Get information on all <span class="math inline">\(n\)</span> data points considered in this analysis.</li>
<li>Perform a residual analysis and look for any systematic patterns in the residuals.</li>
</ol>
</div>
</div>
<div id="model3" class="section level2">
<h2><span class="header-section-number">2.4</span> 5RM#3: Credit Card Balance</h2>
<p>Much like our teacher evaluation data in Section <a href="2-regression.html#model1">2.2</a>, let’s now attempt to identify factors that are associated with how much credit card debt an individual will hold. The textbook <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a> by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani is an intermediate-level textbook on statistical and machine learning freely available <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">here</a>. It has an accompanying R packaged called <code>ISLR</code> with datasets that the authors use to demonstrate various machine learning methods. One dataset that is frequently used by the authors is the <code>Credit</code> dataset where predictions are made on the balance held by various credit card holders based on information like income, credit limit, and education level. Let’s consider the following variables:</p>
<ul>
<li>Outcome variable <span class="math inline">\(y\)</span>: Credit card balance in dollars</li>
<li>Explanatory variables <span class="math inline">\(x\)</span>:
<ul>
<li>income in $1000’s</li>
<li>credit card limit in dollars</li>
<li>credit rating</li>
<li>card holder’s age</li>
<li>years of education</li>
</ul></li>
</ul>
<p>Let’s load the data and <code>select()</code> only the 6 variables listed above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
Credit &lt;-<span class="st"> </span>Credit <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income, Rating, Age, Education)</code></pre></div>
<p>Unfortunately, no information on how this data was sampled was provided, so we’re not able to generalize any such results to a greater population, but we will still use this data to demonstrate <em>multiple regression</em>. Multiple regression is a form of linear regression where there are now more than one explanatory/predictor variables and thus the interpretation of the associated effect of any one explanatory/predictor variable must be made in conjunction with the other explanatory/predictor variable. We’ll perform multiple regression with:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, in this case teaching credit card <code>Balance</code></li>
<li>Two explanatory/predictor variables:
<ol style="list-style-type: decimal">
<li>A first numerical explanatory/predictor variable <span class="math inline">\(x_1\)</span>, in this case credit <code>Limit</code></li>
<li>A second numerical explanatory/predictor variable <span class="math inline">\(x_2\)</span>, in this case <code>Income</code></li>
</ol></li>
</ol>
<div id="model3EDA" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Exploratory data analysis</h3>
<p>Let’s look at the raw data values both by bringing up RStudio’s spreadsheet viewer, although in Table <a href="2-regression.html#tab:model3-data-preview">2.14</a> we only show 5 randomly selected credit card holders out of 400, and using the <code>glimpse()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(Credit)</code></pre></div>
<table>
<caption><span id="tab:model3-data-preview">Table 2.14: </span>Random sample of 5 credit card holders</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
<th align="right">Rating</th>
<th align="right">Age</th>
<th align="right">Education</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>49</td>
<td align="right">0</td>
<td align="right">2252</td>
<td align="right">44.5</td>
<td align="right">205</td>
<td align="right">72</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td>261</td>
<td align="right">345</td>
<td align="right">5184</td>
<td align="right">67.9</td>
<td align="right">383</td>
<td align="right">63</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td>79</td>
<td align="right">391</td>
<td align="right">6662</td>
<td align="right">111.0</td>
<td align="right">468</td>
<td align="right">45</td>
<td align="right">11</td>
</tr>
<tr class="even">
<td>34</td>
<td align="right">0</td>
<td align="right">1829</td>
<td align="right">31.4</td>
<td align="right">162</td>
<td align="right">30</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td>32</td>
<td align="right">0</td>
<td align="right">2733</td>
<td align="right">28.9</td>
<td align="right">210</td>
<td align="right">43</td>
<td align="right">16</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(Credit)</code></pre></div>
<pre><code>Observations: 400
Variables: 6
$ Balance   &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 1407,...
$ Limit     &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 681...
$ Income    &lt;dbl&gt; 14.9, 106.0, 104.6, 148.9, 55.9, 80.2, 21.0, 71.4, 15.1, ...
$ Rating    &lt;int&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, 13...
$ Age       &lt;int&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49, 7...
$ Education &lt;int&gt; 11, 15, 11, 11, 16, 10, 12, 9, 13, 19, 14, 16, 7, 9, 13, ...</code></pre>
<p>Let’s look at some summary statistics:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(Credit)</code></pre></div>
<pre><code>    Balance         Limit           Income          Rating         Age      
 Min.   :   0   Min.   :  855   Min.   : 10.4   Min.   : 93   Min.   :23.0  
 1st Qu.:  69   1st Qu.: 3088   1st Qu.: 21.0   1st Qu.:247   1st Qu.:41.8  
 Median : 460   Median : 4622   Median : 33.1   Median :344   Median :56.0  
 Mean   : 520   Mean   : 4736   Mean   : 45.2   Mean   :355   Mean   :55.7  
 3rd Qu.: 863   3rd Qu.: 5873   3rd Qu.: 57.5   3rd Qu.:437   3rd Qu.:70.0  
 Max.   :1999   Max.   :13913   Max.   :186.6   Max.   :982   Max.   :98.0  
   Education   
 Min.   : 5.0  
 1st Qu.:11.0  
 Median :14.0  
 Mean   :13.4  
 3rd Qu.:16.0  
 Max.   :20.0  </code></pre>
<p>We observe for example</p>
<ol style="list-style-type: decimal">
<li>The typical credit card balance is around $500</li>
<li>The typical credit card limit is around $5000</li>
<li>The typical income is around $40,000.</li>
</ol>
<p>Since our outcome variable <code>Balance</code> and the explanatory/predictor variables <code>Limit</code> and <code>Rating</code> are numerical, we can compute the correlation coefficient between pairs of these variables. However, instead running the <code>cor()</code> command twice, once for each explanatory/predictor variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(Credit<span class="op">$</span>Balance, Credit<span class="op">$</span>Limit)
<span class="kw">cor</span>(Credit<span class="op">$</span>Balance, Credit<span class="op">$</span>Income)</code></pre></div>
<p>We can simultaneously compute them by returning a <em>correlation matrix</em> in Table <a href="2-regression.html#tab:model3-correlation">2.15</a>. We read off the correlation coefficient for any pair of variables by looking them up in the appropriate row/column combination.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre></div>
<table>
<caption><span id="tab:model3-correlation">Table 2.15: </span>Correlations between credit card balance, credit limit, and credit rating</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balance</td>
<td align="right">1.000</td>
<td align="right">0.862</td>
<td align="right">0.464</td>
</tr>
<tr class="even">
<td>Limit</td>
<td align="right">0.862</td>
<td align="right">1.000</td>
<td align="right">0.792</td>
</tr>
<tr class="odd">
<td>Income</td>
<td align="right">0.464</td>
<td align="right">0.792</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>For example, the correlation coefficients of:</p>
<ol style="list-style-type: decimal">
<li><code>Balance</code> with itself is 1</li>
<li><code>Balance</code> with <code>Limit</code> is 0.862, indicating a strong positive linear relationship, which makes sense as only individuals with large credit limits and accrue large credit card balances.</li>
<li><code>Balance</code> with <code>Income</code> is 0.464, suggestive of another positive linear relationship, although not as strong as the relationship between <code>Balance</code> and <code>Limit</code>.</li>
<li>As an added bonus, we can read off the correlation coefficient of the two explanatory/predictor variables, <code>Limit</code> and <code>Income</code> of 0.792. In this case, we say there is a high degree of <em>collinearity</em> between these two explanatory/predictor variables.</li>
</ol>
<p>Let’s visualize the relationship of the outcome variable with each of the two explanatory/predictor variables in two separate plots</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Credit, <span class="kw">aes</span>(<span class="dt">x =</span> Limit, <span class="dt">y =</span> Balance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card balance (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Relationship between balance and credit limit&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)
  
<span class="kw">ggplot</span>(Credit, <span class="kw">aes</span>(<span class="dt">x =</span> Income, <span class="dt">y =</span> Balance)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card balance (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Relationship between balance and income&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:2numxplot1"></span>
<img src="ismaykim_files/figure-html/2numxplot1-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 2.15: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>In both cases, there seems to be a positive relationship. However the two plots in Figure <a href="2-regression.html#fig:2numxplot1">2.15</a> only focus on the relationship of the outcome variable with each of the explanatory/predictor variables independently. To get a sense of the <em>joint</em> relationship of all three variables simultaneously through a visualization, let’s display the data in a 3-dimensional (3D) scatterplot, where</p>
<ol style="list-style-type: decimal">
<li>The numerical outcome variable <span class="math inline">\(y\)</span> <code>Balance</code> is on the z-axis (vertical one)</li>
<li>The two numerical explanatory/predictor variables form the x and y axes (on the floor). In this case
<ol style="list-style-type: decimal">
<li>The first numerical explanatory/predictor variable <span class="math inline">\(x_1\)</span> <code>Income</code> is on the x-axis</li>
<li>The second numerical explanatory/predictor variable <span class="math inline">\(x_2\)</span> <code>Limit</code> is on the y-axis</li>
</ol></li>
</ol>
<p>Click on the following image to open an interactive 3D scatterplot in your browser:</p>
<p><a target="_blank" href="http://rpubs.com/moderndive/credit_card_balance_3D_scatterplot"><img src="images/credit_card_balance_3D_scatterplot.png" title="Example Image Link" width="600"/></a></p>
<p>Previously in Figure <a href="2-regression.html#fig:numxplot4">2.4</a>, we plotted a “best-fitting” regression line through a set of points where the numerical outcome variable <span class="math inline">\(y\)</span> was teaching <code>score</code> and a single numerical explanatory/predictor variable <span class="math inline">\(x\)</span> <code>bty_avg</code>. What is the analogous concept when we have <em>two</em> numerical predictor variables? Instead of a best-fitting line, we now have a best-fitting <em>plane</em>, which is 3D generalization of lines which exist in 2D. Click on the following image to open an interactive plot of the regression plane in your browser.</p>
<p><a target="_blank" href="https://beta.rstudioconnect.com/connect/#/apps/3214/"><img src="images/credit_card_balance_regression_plane.png" title="Example Image Link" width="600"/></a></p>
</div>
<div id="model3table" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Multiple regression</h3>
<p>Just as we did when we had a single numerical explanatory/predictor variable <span class="math inline">\(x\)</span> in Section <a href="2-regression.html#model1table">2.2.2</a> and when we had a single categorical explanatory/predictor variable <span class="math inline">\(x\)</span> in Section <a href="2-regression.html#model2table">2.3.2</a>, we fit a regression model and obtain the regression table in our two numerical explanatory/predictor variable scenario. To fit a regression model and obtain a table using <code>get_regression_table()</code>, we now use a <code>+</code> to consider multiple explanatory/predictor variables. In this case since we want to preform a regression of <code>Limit</code> and <code>Income</code> simultaneously, we input <code>Balance ~ Limit + Income</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_regression_table</span>(Balance <span class="op">~</span><span class="st"> </span>Limit <span class="op">+</span><span class="st"> </span>Income, <span class="dt">data =</span> Credit)</code></pre></div>
<table>
<caption><span id="tab:model3-table-output">Table 2.16: </span>Multiple regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">-385.179</td>
<td align="right">19.465</td>
<td align="right">-19.8</td>
<td align="right">0</td>
<td align="right">-423.446</td>
<td align="right">-346.912</td>
</tr>
<tr class="even">
<td align="left">Limit</td>
<td align="right">0.264</td>
<td align="right">0.006</td>
<td align="right">45.0</td>
<td align="right">0</td>
<td align="right">0.253</td>
<td align="right">0.276</td>
</tr>
<tr class="odd">
<td align="left">Income</td>
<td align="right">-7.663</td>
<td align="right">0.385</td>
<td align="right">-19.9</td>
<td align="right">0</td>
<td align="right">-8.420</td>
<td align="right">-6.906</td>
</tr>
</tbody>
</table>
<p>How do we interpret these three values that define the regression plane?</p>
<ul>
<li>Intercept: -$385.18. The intercept in our case represents the credit card balance for an individual who has both a credit <code>Limit</code> of $0 and <code>Income</code> of $0. In our data however, the intercept has limited practical interpretation as no individuals had <code>Limit</code> or <code>Income</code> values of $0 and furthermore the smallest credit card balance was $0. Rather, it is used to situate the regression plane in 3D space.</li>
<li>Limit: $0.26. Now that we have multiple variables to consider, we have to add a caveat to our interpretation: <em>all other things being equal, for every increase of one unit in credit <code>Limit</code> (dollars), there is an associated increase of on average $0.26 in credit card balance</em>. Note:
<ul>
<li>Just as we did in Section <a href="2-regression.html#model1table">2.2.2</a>, we are not making any causal statements, only statements relating to the association between credit limit and balance</li>
<li>The <em>all other things being equal</em> is making a statement about all other explanatory/predictor variables, in this case only one: <code>Income</code>. This is equivalent to saying “holding <code>Income</code> constant, we observed an associated increase of $0.26 in credit card balance for every dollar increase in credit limit”</li>
</ul></li>
<li>Income: -$7.66. Similarly, <em>all other things being equal, for every increase of one unit in <code>Income</code> (in other words, $1000 in income), there is an associated decrease of on average $7.66 in credit card balance</em>.</li>
</ul>
<p>However, recall in Figure <a href="2-regression.html#fig:2numxplot1">2.15</a> that when considered separately, both <code>Limit</code> and <code>Income</code> had positive relationships with the outcome variable <code>Balance</code>: as card holders’ credit limits increased their credit card balances tended to increase as well, and a similar relationship held for incomes and balances. In the above multiple regression, however, the slope for <code>Income</code> is now -7.66, suggesting a <em>negative relationship</em> between income and credit card balance. What explains these contradictory results? This is a phenomenon known as Simpson’s Paradox, a phenomenon in which a trend appears in several different groups of data but disappears or reverses when these groups are combined; we expand on this in Section <a href="2-regression.html#simpsonsparadox">2.8.4</a>.</p>
</div>
<div id="model3points" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Observed/fitted values and residuals</h3>
<p>As we did previously, in Table <a href="2-regression.html#tab:model3-points-table">2.17</a> let’s unpack the output of the <code>get_regression_points()</code> function for our model for credit card balance</p>
<ul>
<li>for all 400 card holders in the dataset, in other words</li>
<li>for all 400 rows in the <code>Credit</code> data frame, in other words</li>
<li>for all 400 points</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(Balance <span class="op">~</span><span class="st"> </span>Limit <span class="op">+</span><span class="st"> </span>Income, <span class="dt">data =</span> Credit)
regression_points</code></pre></div>
<table>
<caption><span id="tab:model3-points-table">Table 2.17: </span>Regression points (first 5 rows of 400)</caption>
<thead>
<tr class="header">
<th align="right">balance</th>
<th align="right">limit</th>
<th align="right">income</th>
<th align="right">balance_hat</th>
<th align="right">residual</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">333</td>
<td align="right">3606</td>
<td align="right">14.9</td>
<td align="right">454</td>
<td align="right">-120.8</td>
</tr>
<tr class="even">
<td align="right">903</td>
<td align="right">6645</td>
<td align="right">106.0</td>
<td align="right">559</td>
<td align="right">344.3</td>
</tr>
<tr class="odd">
<td align="right">580</td>
<td align="right">7075</td>
<td align="right">104.6</td>
<td align="right">683</td>
<td align="right">-103.4</td>
</tr>
<tr class="even">
<td align="right">964</td>
<td align="right">9504</td>
<td align="right">148.9</td>
<td align="right">986</td>
<td align="right">-21.7</td>
</tr>
<tr class="odd">
<td align="right">331</td>
<td align="right">4897</td>
<td align="right">55.9</td>
<td align="right">481</td>
<td align="right">-150.0</td>
</tr>
</tbody>
</table>
<p>Recall the format of the output:</p>
<ul>
<li><code>balance</code> corresponds to <span class="math inline">\(y\)</span> the observed value</li>
<li><code>balance_hat</code> corresponds to <span class="math inline">\(\widehat{y}\)</span> the fitted value</li>
<li><code>reisdual</code> corresponds to the residual <span class="math inline">\(y - \widehat{y}\)</span></li>
</ul>
<p>As we did in Section <a href="2-regression.html#model1points">2.2.3</a> let’s prove to ourselves that the results make sense by manually replicate the internal computation that <code>get_regression_points()</code> performs using the <code>mutate()</code> verb from Chapter <a href="#wrangling"><strong>??</strong></a></p>
<ol style="list-style-type: decimal">
<li>First we compute a duplicate of the fitted values <span class="math inline">\(\widehat{y} = b_0 + b_1 \times x_1 + b_2 \times x_2\)</span> where the intercept <span class="math inline">\(b_0\)</span> = -385.179, the slope <span class="math inline">\(b_1\)</span> for <code>Limit</code> of 0.264, and the slope <span class="math inline">\(b_2\)</span> for <code>Income</code> of -7.663 and store these in <code>balance_hat_2</code></li>
<li>Then we compute the a duplicated the residuals <span class="math inline">\(y - \widehat{y}\)</span> and store these in <code>residual_2</code></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span>regression_points <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">balance_hat_2 =</span> <span class="op">-</span><span class="fl">385.179</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.264</span> <span class="op">*</span><span class="st"> </span>limit <span class="op">-</span><span class="st"> </span><span class="fl">7.663</span> <span class="op">*</span><span class="st"> </span>income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">residual_2 =</span> balance <span class="op">-</span><span class="st"> </span>balance_hat_<span class="dv">2</span>)
regression_points</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-45">Table 2.18: </span>Regression points (first five rows)</caption>
<thead>
<tr class="header">
<th align="right">balance</th>
<th align="right">limit</th>
<th align="right">income</th>
<th align="right">balance_hat</th>
<th align="right">residual</th>
<th align="right">balance_hat_2</th>
<th align="right">residual_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">333</td>
<td align="right">3606</td>
<td align="right">14.9</td>
<td align="right">454</td>
<td align="right">-120.8</td>
<td align="right">453</td>
<td align="right">-119.7</td>
</tr>
<tr class="even">
<td align="right">903</td>
<td align="right">6645</td>
<td align="right">106.0</td>
<td align="right">559</td>
<td align="right">344.3</td>
<td align="right">557</td>
<td align="right">346.4</td>
</tr>
<tr class="odd">
<td align="right">580</td>
<td align="right">7075</td>
<td align="right">104.6</td>
<td align="right">683</td>
<td align="right">-103.4</td>
<td align="right">681</td>
<td align="right">-101.1</td>
</tr>
<tr class="even">
<td align="right">964</td>
<td align="right">9504</td>
<td align="right">148.9</td>
<td align="right">986</td>
<td align="right">-21.7</td>
<td align="right">983</td>
<td align="right">-18.7</td>
</tr>
<tr class="odd">
<td align="right">331</td>
<td align="right">4897</td>
<td align="right">55.9</td>
<td align="right">481</td>
<td align="right">-150.0</td>
<td align="right">479</td>
<td align="right">-148.4</td>
</tr>
</tbody>
</table>
<p>We see that our manually computed variables <code>balance_hat_2</code> and <code>residual_2</code> equal the original results (up to rounding error).</p>
</div>
<div id="model3residuals" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Residual analysis</h3>
<p>Recall in Section <a href="2-regression.html#model1residuals">2.2.4</a>, our first residual analysis plot investigated the presense of any systematic pattern in the residuals when we had a single numerical predictor: <code>bty_age</code>. For the <code>Credit</code> card dataset, since we have two numerical predictors, <code>Limit</code> and <code>Income</code>, we must perform this twice:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> limit, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Residuals vs credit limit&quot;</span>)
  
<span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> income, <span class="dt">y =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residual&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Residuals vs income&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-47"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-47-1.png" alt="Residuals vs credit limit and income" width="\textwidth" />
<p class="caption">
Figure 2.16: Residuals vs credit limit and income
</p>
</div>
<p>In this case, there does appear to be a systematic pattern to the residuals, as the scatter of the residuals around the line <span class="math inline">\(y=0\)</span> is definitely not consistent. This behavior of the residuals is further evidenced by the histogram of residuals in Figure @ref(fig:model3_residuals_hist). We observe that the residuals have a slight right-skew (a long tail towards the right). Ideally, these residuals should be bell-shaped around a residual value of 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(regression_points, <span class="kw">aes</span>(<span class="dt">x =</span> residual)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Residual&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/model3_residuals_hist-1.png" alt="Plot of residuals over continent" width="\textwidth" />
<p class="caption">
(#fig:model3_residuals_hist)Plot of residuals over continent
</p>
</div>
<p>Another way to intepret this histogram is that since the residual is computed as <span class="math inline">\(y - \widehat{y}\)</span> = <code>balance</code> - <code>balance_hat</code>, we have some values where the fitted value <span class="math inline">\(\widehat{y}\)</span> is very much lower than the observed value <span class="math inline">\(y\)</span>. In other words, we are underfitting certain credit card holder’s balance by a very large amount.</p>
</div>
<div id="your-turn-2" class="section level3">
<h3><span class="header-section-number">2.4.5</span> Your turn</h3>
<p>Repeat this same analysis but using <code>Age</code> and <code>Rating</code> as the two numerical explanatory/predictor variables. Recall the four steps we’ve been following:</p>
<ol style="list-style-type: decimal">
<li>Perform an exploratory data analysis</li>
<li>Fit a linear regression model and get information about the model</li>
<li>Get information on all <span class="math inline">\(n\)</span> data points considered in this analysis.</li>
<li>Perform a residual analysis and look for any systematic patterns in the residuals.</li>
</ol>
</div>
</div>
<div id="model4" class="section level2">
<h2><span class="header-section-number">2.5</span> 5RM#4: Teacher Evaluations Part II</h2>
<p>Let’s revisit the professor evaluation data introduced in Section <a href="2-regression.html#model1">2.2</a>, where we studied the relationship between</p>
<ol style="list-style-type: decimal">
<li>the numerical outcome variable <span class="math inline">\(y\)</span>: instructor evaluation score <code>score</code></li>
<li>the numerical explanatory/predictor variable <span class="math inline">\(x\)</span>: beauty score <code>bty_avg</code></li>
</ol>
<p>This analysis suggested that there is a positive relationship between <code>bty_avg</code> and <code>score</code>, in other words as instructors had higher beauty scores, they also tended to have higher teaching evaluation scores. Now let’s say we want to study the relationship between an instructor’s teaching score as a function of the instructor’s age instead their beauty score along with the instructor’s binary gender. Our modeling situation now becomes</p>
<ol style="list-style-type: decimal">
<li>the numerical outcome variable <span class="math inline">\(y\)</span>: instructor evaluation score <code>score</code></li>
<li>Two explanatory/predictor variables:
<ol style="list-style-type: decimal">
<li>A first numerical explanatory/predictor variable <span class="math inline">\(x_1\)</span>: <code>age</code></li>
<li>A second numerical explanatory/predictor variable <span class="math inline">\(x_2\)</span>, in this case <code>gender</code></li>
</ol></li>
</ol>
<div id="model4EDA" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Exploratory data analysis</h3>
<p>We’ve already performed some elements of our exploratory data analysis in Section <a href="2-regression.html#model4EDA">2.5.1</a>, in particular of the outcome variable <code>score</code>, so let’s now only consider our two new explanatory/predictor variables</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">evals <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(age, gender) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summary</span>()</code></pre></div>
<pre><code>      age          gender         
 Min.   :29.0   Length:463        
 1st Qu.:42.0   Class :character  
 Median :48.0   Mode  :character  
 Mean   :48.4                     
 3rd Qu.:57.0                     
 Max.   :73.0                     </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(evals<span class="op">$</span>score, evals<span class="op">$</span>age)</code></pre></div>
<pre><code>[1] -0.107</code></pre>
<p>In Figure <a href="#numxcatxplot1"><strong>??</strong></a>, we plot a scatterplot of <code>score</code> over <code>age</code>, but given that <code>gender</code> is a binary categorical variable</p>
<ol style="list-style-type: decimal">
<li>We can assign a color to points from each of the two levels of <code>gender</code>: female and male</li>
<li>Furthermore, the <code>geom_smooth(method = &quot;lm&quot;, se = FALSE)</code> layer automatically fits a different regression line for each</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> score, <span class="dt">col =</span> gender)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;Gender&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxcatxplot1"></span>
<img src="ismaykim_files/figure-html/numxcatxplot1-1.png" alt="Instructor evaluation scores at UT Austin split by gender: Jittered" width="\textwidth" />
<p class="caption">
Figure 2.17: Instructor evaluation scores at UT Austin split by gender: Jittered
</p>
</div>
<p>We notice some interesting trends:</p>
<ol style="list-style-type: decimal">
<li>There are almost no women faculty over the age of 60.</li>
<li>Fitting separate regression lines for men and women, we see they have different slopes. We see that the associated effect of increasing age seems to be much harsher for women than men. In other words, they have different slopes.</li>
</ol>
</div>
<div id="model4table" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Multiple regression</h3>
<p>Let’s now compute the <em>regression table</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_regression_table</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> evals)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-51">Table 2.19: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">4.484</td>
<td align="right">0.125</td>
<td align="right">35.79</td>
<td align="right">0.000</td>
<td align="right">4.238</td>
<td align="right">4.730</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">-0.009</td>
<td align="right">0.003</td>
<td align="right">-3.28</td>
<td align="right">0.001</td>
<td align="right">-0.014</td>
<td align="right">-0.003</td>
</tr>
<tr class="odd">
<td align="left">gendermale</td>
<td align="right">0.191</td>
<td align="right">0.052</td>
<td align="right">3.63</td>
<td align="right">0.000</td>
<td align="right">0.087</td>
<td align="right">0.294</td>
</tr>
</tbody>
</table>
<p>The modeling equation for this is:</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1 x_1 + b_2 x_2 \\
\widehat{score} &amp;= b_0 + b_{age} age + b_{male} \mathbb{1}[\mbox{is male}] \\
\end{align}
\]</span></p>
<p>What this looks like is in Figure <a href="2-regression.html#fig:numxcatxplot2">2.18</a> below.</p>
<div class="figure" style="text-align: center"><span id="fig:numxcatxplot2"></span>
<img src="ismaykim_files/figure-html/numxcatxplot2-1.png" alt="Instructor evaluation scores at UT Austin by gender: same slope" width="\textwidth" />
<p class="caption">
Figure 2.18: Instructor evaluation scores at UT Austin by gender: same slope
</p>
</div>
<p>We see that:</p>
<ul>
<li>Females are treated as the baseline for comparison for no other reason than “female” is alphabetically earlier than “male”. The <span class="math inline">\(b_{male} = 0.1906\)</span> is the vertical “bump” that men get in their teaching evaluation scores. Or more precisely, it is the average difference in teaching score that men get <em>relative to the baseline of women</em></li>
<li>Accordingly, the intercepts are (which in this case make no sense since no professor can have age 0):
<ul>
<li>for women: <span class="math inline">\(b_0\)</span> = 4.484</li>
<li>for men: <span class="math inline">\(b_0 + b_{male}\)</span> = 4.484 + 0.191 = 4.675</li>
</ul></li>
<li>Both men and women have the same slope. In other words, <em>in this model</em> the associated effect of age is the same for men and women: all other things being equal, for every increase in 1 in age, there is on average an associated decrease of <span class="math inline">\(b_{age}\)</span> = -0.0086 in teaching score</li>
</ul>
<p><strong>Hold up</strong>: Figure <a href="2-regression.html#fig:numxcatxplot2">2.18</a> is different than Figure <a href="2-regression.html#fig:numxcatxplot1">2.17</a>! What is going on? What we have in the original plot is an <em>interaction effect</em> between age and gender!</p>
</div>
<div id="mutiple-regression-with-interaction-effects" class="section level3">
<h3><span class="header-section-number">2.5.3</span> Mutiple regression with interaction effects</h3>
</div>
<div id="model4points" class="section level3">
<h3><span class="header-section-number">2.5.4</span> Observed/fitted values and residuals</h3>
<p>We say a model has an interaction effect if the associated effect of one variable <em>depends on the value of another variable</em>.</p>
<p>Let’s now compute the <em>regression table</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_regression_table</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">*</span><span class="st"> </span>gender, <span class="dt">data =</span> evals)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-53">Table 2.20: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">4.883</td>
<td align="right">0.205</td>
<td align="right">23.80</td>
<td align="right">0.000</td>
<td align="right">4.480</td>
<td align="right">5.286</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">-0.018</td>
<td align="right">0.004</td>
<td align="right">-3.92</td>
<td align="right">0.000</td>
<td align="right">-0.026</td>
<td align="right">-0.009</td>
</tr>
<tr class="odd">
<td align="left">gendermale</td>
<td align="right">-0.446</td>
<td align="right">0.265</td>
<td align="right">-1.68</td>
<td align="right">0.094</td>
<td align="right">-0.968</td>
<td align="right">0.076</td>
</tr>
<tr class="even">
<td align="left">age:gendermale</td>
<td align="right">0.014</td>
<td align="right">0.006</td>
<td align="right">2.45</td>
<td align="right">0.015</td>
<td align="right">0.003</td>
<td align="right">0.024</td>
</tr>
</tbody>
</table>
<p>The model formula is</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1 x_1 + b_2 x_2 + b_3 x_1x_2\\
\widehat{score} &amp;= b_0 + b_{age} age + b_{male} \mathbb{1}[\mbox{is male}] + b_{age,male}age\mathbb{1}[\mbox{is male}] \\
\end{align}
\]</span></p>
</div>
<div id="model4residuals" class="section level3">
<h3><span class="header-section-number">2.5.5</span> Residual analysis</h3>
</div>
</div>
<div id="model5" class="section level2">
<h2><span class="header-section-number">2.6</span> 5RM#5: Biographical Movies</h2>
<p>Let’s look at the <code>biopics</code> dataset in the <a href="https://rudeboybert.github.io/fivethirtyeight/"><code>fivethirtyeight</code></a> package. After loading the package, run <code>?biopics</code> in the console to read the help file. This data is from the article <a href="https://fivethirtyeight.com/features/straight-outta-compton-is-the-rare-biopic-not-about-white-dudes/">“Straight Outta Compton” Is The Rare Biopic Not About White Dudes</a>.</p>
<p>First let’s load the data and look at a random sample of 5 rows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(fivethirtyeight)
biopics &lt;-<span class="st"> </span>biopics <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(title, box_office, person_of_color, subject_sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Remove those that are missing</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(box_office))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">box_office</th>
<th align="left">person_of_color</th>
<th align="left">subject_sex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Nostradamus</td>
<td align="right">364000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="even">
<td align="left">Nora</td>
<td align="right">12300</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">Swoon</td>
<td align="right">340000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="even">
<td align="left">Salome’s Last Dance</td>
<td align="right">331000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">Monster</td>
<td align="right">34500000</td>
<td align="left">FALSE</td>
<td align="left">Female</td>
</tr>
</tbody>
</table>
<p>Before we conduct an exploratory data analysis of the <code>biopics</code> data, let’s first have a discussion <span class="math inline">\(\log\)</span>-transformations.</p>
<div id="log-transformations" class="section level3">
<h3><span class="header-section-number">2.6.1</span> log-transformations</h3>
<p>Let’s consider a histogram of the box office revenues for the <code>biopics</code> dataset</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(biopics, <span class="kw">aes</span>(<span class="dt">x =</span> box_office)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Box office revenue&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:logtransform1"></span>
<img src="ismaykim_files/figure-html/logtransform1-1.png" alt="Histogram of box office revenue" width="\textwidth" />
<p class="caption">
Figure 2.19: Histogram of box office revenue
</p>
</div>
<p>In Figure <a href="2-regression.html#fig:logtransform1">2.19</a>, we see there is a right-skew to both the x-values. This is because there are a few Hollywood blockbusters being compared with many (likely) smaller-scale independent films. Let’s look at the top 5 and bottom 5 grossing movies in this dataset:</p>
<table>
<caption><span id="tab:unnamed-chunk-56">Table 2.21: </span>Top 5 grossing movies in data</caption>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">box_office</th>
<th align="left">person_of_color</th>
<th align="left">subject_sex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">American Sniper</td>
<td align="right">350000000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="even">
<td align="left">The Blind Side</td>
<td align="right">256000000</td>
<td align="left">TRUE</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">Lincoln</td>
<td align="right">182000000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="even">
<td align="left">A Beautiful Mind</td>
<td align="right">171000000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">Catch Me If You Can</td>
<td align="right">164000000</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:unnamed-chunk-57">Table 2.22: </span>Bottom 5 grossing movies in data</caption>
<thead>
<tr class="header">
<th align="left">title</th>
<th align="right">box_office</th>
<th align="left">person_of_color</th>
<th align="left">subject_sex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Caravaggio</td>
<td align="right">3150</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="even">
<td align="left">Set Fire to the Stars</td>
<td align="right">3270</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">My Dinner with Andre</td>
<td align="right">5070</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="even">
<td align="left">My Dinner with Andre</td>
<td align="right">5070</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
<tr class="odd">
<td align="left">Kid Cannabis</td>
<td align="right">5570</td>
<td align="left">FALSE</td>
<td align="left">Male</td>
</tr>
</tbody>
</table>
<p>The scale of box office revenue is completely different! Hence, in Figure <a href="2-regression.html#fig:logtransform1">2.19</a>, it’s really hard to see what’s going on at the lower-end.</p>
<p>Let’s unskew this variable and compare not <em>absolute</em> differences, but rather, <em>relative</em> differences i.e. differences in “order of magnitude” using a <code>log10()</code> transformation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(biopics, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log10</span>(box_office))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log10(Box office revenue)&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:logtransform2"></span>
<img src="ismaykim_files/figure-html/logtransform2-1.png" alt="Histogram of log10(box office revenue)" width="\textwidth" />
<p class="caption">
Figure 2.20: Histogram of log10(box office revenue)
</p>
</div>
<p>We can see a little better what’s going on at the lower end of the box office revenue scale. However the values on the axes require a little thinking to process. For example at <span class="math inline">\(x=7\)</span>, this corresponds to movies with revenue of <span class="math inline">\(10^7 = 10,000,000\)</span> dollars. So instead, let’s <em>rescale</em> the x-axis so that it displays the data in their original units.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(biopics, <span class="kw">aes</span>(<span class="dt">x =</span> box_office)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Box office revenue (log10-scale))&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:logtransform3"></span>
<img src="ismaykim_files/figure-html/logtransform3-1.png" alt="Histogram of box office revenue (log-10 scale)" width="\textwidth" />
<p class="caption">
Figure 2.21: Histogram of box office revenue (log-10 scale)
</p>
</div>
<p>Note that</p>
<ul>
<li>The two plots are identical, but the values on the x-axis are different.</li>
<li>In both Figure <a href="2-regression.html#fig:logtransform2">2.20</a> Figure <a href="2-regression.html#fig:logtransform3">2.21</a>, equivalent distances on each axes correspond to not equivalent absolute differences, but equivalent relative/multiplicative differences. So for example, the horizontal distance on the plot from Budget = <code>1e+05</code> = <span class="math inline">\(10^5\)</span> to Budget = <code>1e+06</code> = <span class="math inline">\(10^6\)</span> is equal to the horizontal distance on the plot from Budget = <code>1e+06</code> = <span class="math inline">\(10^6\)</span> to Budget = <code>1e+07</code> = <span class="math inline">\(10^7\)</span>.</li>
</ul>
</div>
<div id="model5EDA" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Exploratory data analysis</h3>
<p>Let’s now consider the box office gross earnings in the US of these movies on a log10 scale:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(biopics, <span class="kw">aes</span>(<span class="dt">x =</span> subject_sex, <span class="dt">y =</span> box_office)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>person_of_color, <span class="dt">nrow =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_log10</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Subject sex&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Box office revenue (log10-scale)&quot;</span>, <span class="dt">title =</span>
  <span class="st">&quot;Person of color?&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:2catxplot"></span>
<img src="ismaykim_files/figure-html/2catxplot-1.png" alt="Box office revenue vs biopic subject info" width="\textwidth" />
<p class="caption">
Figure 2.22: Box office revenue vs biopic subject info
</p>
</div>
<p>It seems in this dataset, men of color had the highest median box office gross. Let’s look at a table of means instead of medians.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">biopics <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(person_of_color, subject_sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean_box_office =</span> <span class="kw">mean</span>(box_office)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(mean_box_office))</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-59">Table 2.23: </span>Group means</caption>
<thead>
<tr class="header">
<th align="left">person_of_color</th>
<th align="left">subject_sex</th>
<th align="right">mean_box_office</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">TRUE</td>
<td align="left">Male</td>
<td align="right">31648028</td>
</tr>
<tr class="even">
<td align="left">FALSE</td>
<td align="left">Male</td>
<td align="right">22871074</td>
</tr>
<tr class="odd">
<td align="left">TRUE</td>
<td align="left">Female</td>
<td align="right">20035820</td>
</tr>
<tr class="even">
<td align="left">FALSE</td>
<td align="left">Female</td>
<td align="right">18088799</td>
</tr>
</tbody>
</table>
<p>Keep in mind two things though. First, the sample sizes are different:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">biopics <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(person_of_color, subject_sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-61">Table 2.24: </span>Number of movies of each type in dataset</caption>
<thead>
<tr class="header">
<th align="left">person_of_color</th>
<th align="left">subject_sex</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">FALSE</td>
<td align="left">Male</td>
<td align="right">268</td>
</tr>
<tr class="even">
<td align="left">FALSE</td>
<td align="left">Female</td>
<td align="right">93</td>
</tr>
<tr class="odd">
<td align="left">TRUE</td>
<td align="left">Male</td>
<td align="right">61</td>
</tr>
<tr class="even">
<td align="left">TRUE</td>
<td align="left">Female</td>
<td align="right">15</td>
</tr>
</tbody>
</table>
<p>Second, can we <em>generalize</em> these results to <em>all movies</em>? How was the selection of movies sampled? Is it a representative sample of all movies, or was their a systematic reason these were included?</p>
</div>
<div id="model5table" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Multiple regression</h3>
<p>Let’s now compute the <em>regression table</em>. Let’s jump straight into considering a model that incorporates an interaction term as described earlier.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_regression_table</span>(box_office <span class="op">~</span><span class="st"> </span>person_of_color <span class="op">*</span><span class="st"> </span>subject_sex, <span class="dt">data =</span> biopics)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-63">Table 2.25: </span>Regression table</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std_error</th>
<th align="right">statistic</th>
<th align="right">p_value</th>
<th align="right">conf_low</th>
<th align="right">conf_high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept</td>
<td align="right">18088799</td>
<td align="right">3964762</td>
<td align="right">4.562</td>
<td align="right">0.000</td>
<td align="right">10296227</td>
<td align="right">25881371</td>
</tr>
<tr class="even">
<td align="left">person_of_colorTRUE</td>
<td align="right">1947021</td>
<td align="right">10638573</td>
<td align="right">0.183</td>
<td align="right">0.855</td>
<td align="right">-18962645</td>
<td align="right">22856687</td>
</tr>
<tr class="odd">
<td align="left">subject_sexMale</td>
<td align="right">4782275</td>
<td align="right">4601541</td>
<td align="right">1.039</td>
<td align="right">0.299</td>
<td align="right">-4261860</td>
<td align="right">13826410</td>
</tr>
<tr class="even">
<td align="left">person_of_colorTRUE:subject_sexMale</td>
<td align="right">6829933</td>
<td align="right">11941509</td>
<td align="right">0.572</td>
<td align="right">0.568</td>
<td align="right">-16640597</td>
<td align="right">30300464</td>
</tr>
</tbody>
</table>
<p>The model formula is</p>
<p><span class="math display">\[
\begin{align}
\widehat{y} &amp;= b_0 + b_1 x_1 + b_2 x_2 + b_3 x_1x_2\\
\widehat{score} &amp;= b_0 + b_{color}\mathbb{1}[\mbox{of color}] + b_{male} \mathbb{1}[\mbox{is male}] + b_{color,male}\mathbb{1}[\mbox{of color}]\mathbb{1}[\mbox{is male}] \\
\end{align}
\]</span></p>
<p>Recreate four group means from the Table 6.15 above:</p>
<ul>
<li>Female not of color: 18088799 = 18088799 = <span class="math inline">\(b_0\)</span>. Note: <em>Women not of color are the baseline group</em>.</li>
<li>Male not of color: 22871074 = 18088799 + 4782275 = <span class="math inline">\(b_0 + b_{male}\)</span></li>
<li>Female of color: 20035820 = 18088799 + 1947021 = <span class="math inline">\(b_0 + b_{color}\)</span></li>
<li>Male of color: 31648028 = 18088799 + 1947021 + 4782275 + 6829933 = <span class="math inline">\(b_0 + b_{color} + b_{male} + b_{color,male}\)</span>. Note: <span class="math inline">\(b_{color,male}\)</span> is the <em>interaction term</em>.</li>
</ul>
</div>
<div id="model5points" class="section level3">
<h3><span class="header-section-number">2.6.4</span> Observed/fitted values and residuals</h3>
</div>
<div id="model5residuals" class="section level3">
<h3><span class="header-section-number">2.6.5</span> Residual analysis</h3>
</div>
</div>
<div id="inference-for-regression" class="section level2">
<h2><span class="header-section-number">2.7</span> Inference for regression</h2>
<p>In Chapter <a href="2-regression.html#inference-for-regression">2.7</a>, we’ll revisit regression after the</p>
</div>
<div id="other-topics" class="section level2">
<h2><span class="header-section-number">2.8</span> Other topics</h2>
<div id="correlationcoefficient" class="section level3">
<h3><span class="header-section-number">2.8.1</span> Correlation coefficient</h3>
<p>What if in instead we looked the correlation coefficient between <code>Income</code> and credit card <code>Balance</code>, where <code>Income</code> was in dollars and not thousands of dollars? i.e. we multiply <code>Income</code> by 1000?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Credit <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Balance, Limit, Income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Income =</span> Income <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-65">Table 2.26: </span>Correlation between income (in $) and credit card balance</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Balance</th>
<th align="right">Limit</th>
<th align="right">Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Balance</td>
<td align="right">1.000</td>
<td align="right">0.862</td>
<td align="right">0.464</td>
</tr>
<tr class="even">
<td>Limit</td>
<td align="right">0.862</td>
<td align="right">1.000</td>
<td align="right">0.792</td>
</tr>
<tr class="odd">
<td>Income</td>
<td align="right">0.464</td>
<td align="right">0.792</td>
<td align="right">1.000</td>
</tr>
</tbody>
</table>
<p>We see it is the same! We say that correlation coefficient is invariant to linear transformations! In other words</p>
<ul>
<li>The correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> will be the same as</li>
<li>The correlation between <span class="math inline">\(a\times x + b\)</span> and <span class="math inline">\(y\)</span> where <span class="math inline">\(a, b\)</span> are numerical values (real numbers in mathematical terms)</li>
</ul>
</div>
<div id="leastsquares" class="section level3">
<h3><span class="header-section-number">2.8.2</span> Best fitting line</h3>
<p>Regression lines are also known as “best fitting lines”. But what do we mean by best? Let’s unpack the criteria that is used by regression to determine best. Recall the plot in Figure <a href="2-regression.html#fig:numxplot5">2.5</a> where for a professor with a beauty average score of <span class="math inline">\(x=7.333\)</span></p>
<ul>
<li>The observed value <span class="math inline">\(y=4.9\)</span> was marked with a red circle</li>
<li>The fitted value <span class="math inline">\(\widehat{y} = 4.369\)</span> on the regression line was marked with a red square</li>
<li>The residual <span class="math inline">\(y-\widehat{y} = 4.9-4.369 = 0.531\)</span> was the length of the blue arrow.</li>
</ul>
<p>Let’s do this for another arbitrarily chosen professor whose beauty score was <span class="math inline">\(x=2.333\)</span>. The residual in this case is <span class="math inline">\(2.7 - 4.036 = -1.336\)</span>.</p>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-66-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Let’s do this for another arbitrarily chosen professor whose beauty score was <span class="math inline">\(x=3.667\)</span>. The residual in this case is <span class="math inline">\(4.4 - 4.125 = 0.2753\)</span>.</p>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-67-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Let’s do this for another arbitrarily chosen professor whose beauty score was <span class="math inline">\(x=6\)</span>. The residual in this case is <span class="math inline">\(3.8 - 4.28 = -0.4802\)</span>.</p>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-68-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Now let’s say we repeated this process for all 463 professors in our dataset. Regression <em>minimizes the sum of all 463 arrow lengths squared.</em> In other words, it minimizes the sum of the squared residuals:</p>
<p><span class="math display">\[
\sum_{i=1}^{n}(y_i - \widehat{y}_i)^2
\]</span></p>
<p>We square the arrow lengths so that positive and negative deviations of the same amount are treated equally. That’s why alternative names for the simple linear regression line are the <strong>least-squares line</strong> and the <strong>best fitting line</strong>. It can be proven via calculus and linear algebra that this line uniquely minimizes the sum of the squared arrow lengths.</p>
<p>For the regression line in the plot, the sum of the squared residuals is 131.879.</p>
</div>
<div id="underthehood" class="section level3">
<h3><span class="header-section-number">2.8.3</span> How does <code>get_regression_table()</code> work?</h3>
</div>
<div id="simpsonsparadox" class="section level3">
<h3><span class="header-section-number">2.8.4</span> Simpson’s Paradox</h3>
<p>Recall in Section <a href="2-regression.html#model3">2.4</a>, we saw the two following seemingly contraditory results when studying the relationship between credit card balance, credit limit, and income. On the one hand, the right hand plot of Figure <a href="2-regression.html#fig:2numxplot1">2.15</a> suggested that credit card balance and income were positively related:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-69"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-69-1.png" alt="Relationship between credit card balance and credit limit/income" width="\textwidth" />
<p class="caption">
Figure 2.23: Relationship between credit card balance and credit limit/income
</p>
</div>
<p>On the other hand, the multiple regression in Table <a href="2-regression.html#tab:model3-table-output">2.16</a>, suggested that when modeling credit card balance as a function of both credit limit and income at the same time, credit limit has a negative relationship with balance, as evidenced by the slope of -7.66. How can this be?</p>
<p>First, let’s dive a little deeper into the explanatory/predictor variable <code>Limit</code>. Figure @ref(fig:credit_limit_quartiles) shows a histogram of all 400 values of <code>Limit</code>, along with vertical red lines that cut up the data into quartiles, meaning:</p>
<ol style="list-style-type: decimal">
<li>25% of credit limits were between $0 and $3088. Let’s call this the “low” credit limit bracket.</li>
<li>25% of credit limits were between $3088 and $4622. Let’s call this the “medium-low” credit limit bracket.</li>
<li>25% of credit limits were between $4622 and $5873. Let’s call this the “medium-high” credit limit bracket.</li>
<li>25% of credit limits were over $5873. Let’s call this the “high” credit limit bracket.</li>
</ol>
<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/credit_limit_quartiles-1.png" alt="Histogram of credit limits and quartiles" width="\textwidth" />
<p class="caption">
(#fig:credit_limit_quartiles)Histogram of credit limits and quartiles
</p>
</div>
<p>Let’s now display</p>
<ol style="list-style-type: decimal">
<li>The scatterplot showing the relationship between credit card balance and limit (the right-hand plot of Figure <a href="2-regression.html#fig:2numxplot1">2.15</a>).</li>
<li>The scatterplot showing the relationship between credit card balance and limit now with a color aesthetic added corresponding to the credit limit bracket.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:2numxplot4"></span>
<img src="ismaykim_files/figure-html/2numxplot4-1.png" alt="Relationship between credit card balance and income for different credit limit brackets" width="\textwidth" />
<p class="caption">
Figure 2.24: Relationship between credit card balance and income for different credit limit brackets
</p>
</div>
<p>The left-hand plot focuses of the relationship between balance and income in aggregate, but the right-hand plot focuses on the relationship between balance and income <em>broken down by credit limit bracket</em>. Whereas in aggregate there is an overall positive relationship, but when broken down We now see that for the</p>
<ol style="list-style-type: decimal">
<li>low</li>
<li>medium-low</li>
<li>medium-high</li>
</ol>
<p>income bracket groups, the strong positive relationship between credit card balance and income disappears! Only for the high bracket does the relationship stay somewhat positive. In this example credit limit is a <em>confounding variable</em> for credit card balance and income.</p>
<!--
Alternatively, we could also have used facets, where each facet has roughly 25% of people based
on the credit limit bracket. However, IMO the above plot is easier to read.

<div class="figure" style="text-align: center">
<img src="ismaykim_files/figure-html/2numxplot5-1.png" alt="Relationship between credit card balance and income for different credit limit brackets" width="\textwidth" />
<p class="caption">(\#fig:2numxplot5)Relationship between credit card balance and income for different credit limit brackets</p>
</div>
-->

<div id="refs" class="references">
<div>
<p>Chihara, Laura M., and Tim C. Hesterberg. 2011. <em>Mathematical Statistics with Resampling and R</em>. Hoboken, NJ: John Wiley; Sons. <a href="https://sites.google.com/site/chiharahesterberg/home" class="uri">https://sites.google.com/site/chiharahesterberg/home</a>.</p>
</div>
<div>
<p>Diez, David M, Christopher D Barr, and Mine Çetinkaya-Rundel. 2014. <em>Introductory Statistics with Randomization and Simulation</em>. First Edition. <a href="https://www.openintro.org/stat/textbook.php?stat_book=isrs" class="uri">https://www.openintro.org/stat/textbook.php?stat_book=isrs</a>.</p>
</div>
<div>
<p>Grolemund, Garrett, and Hadley Wickham. 2016. <em>R for Data Science</em>. <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a>.</p>
</div>
<div>
<p>Xie, Yihui. 2017. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown" class="uri">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ismayc/moderndiver-book/edit/master/06-regression.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
